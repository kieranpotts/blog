= Hypermedia APIs
Kieran Potts, 20 July 2025
:description: TODO: Add description...
:docinfo: shared
:nofooter:

:link-fielding-2008:   https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven

// TODO: Add introduction...

When you go to the homepage for a website you've never been to before, you can intuitively find your way around and discover all the resources the site has to offer. You do that by interacting with hyperlinks and forms that are embedded within the webpages.

We take "surfing the web" for granted now, but this idea of resources being discoverable by following hypermedia controls embedded directly in the content was one of the great innovations of the World Wide Web.

Roy Fielding, in his https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm[distinguished PhD thesis], published in 2000, wrote that the concept of using "hypermedia as the engine of application state" (HATEOAS) was central to the early design of the web platform. When a web browser makes a request to a server, the server responds not only with the requested resource, which updates the client application's state, but also with information about additional operations now available to the client application given its new state. Those operations are encoded in the response messages as hypermedia – links and forms embedded in the HTML document generated by the server. Users choose their next actions from the available hypermedia controls that are presented to them.

By using hypermedia in server responses as the primary means to drive application state, client applications are left to be quite simple and generic. A web browser is the quintessential dumb client application. In order to render webpages, a web browser requires no hard-coded knowledge of each web server's available resources. It needs only an understanding of general-purpose media types and protocols: HTTP, URI, HTML, etc.

The principle of HATEOAS means that the contracts that clients and servers use to interact with one another come in the form of *media types*. In the case of the web, that media type is HTML. The HTML media type defines generic hypermedia controls that allow clients to discover all the resources and operations offered by a server.

An HTML `<form>` element is an example of a generic hypermedia control. Via this control, the server can specify the location of a resource and all the fields required to submit data to that resource. The client does not need any prior information about any of this, it just needs to understand the semantics of the `<form>` control.

This design was a pivotal factor in the World Wide Web becoming the runaway success it was. This incredible level of decoupling between clients and servers is what allowed the web to scale like no other distributed information system before it. Web clients (browsers) did not need to know anything about the resources and operations made available by any particular server, and servers did not need to maintain any state about their clients. This architecture made it possible for the web to evolve into a universal application platform – all the services and content we now use every day.

== Bringing hypermedia to web service APIs

Besides the GUIs of websites and webapps, could we apply the HATEOAS design principle to web service APIs, too? Could we design hypermedia-driven APIs such that generic client applications could discover and interact with the resources and operations of _multiple_ web services without any hard-coded knowledge of those services?

A hypermedia-driven API would see a client and server be programmed to share only a common media format, which the server would use to encode hypermedia controls in its response messages, and which in turn client applications would use to discover and navigate the available resources and execute available operations.

This is very different to how almost all web service APIs are designed today. To interact with a web service API, client programs typically need lots of hard-coded logic about the API's endpoints, authentication methods, and the data schema of the resources it exposes. Thus, client applications become tightly coupled to the interfaces of the APIs that back them.

This has all sorts of consequences. Maintenance costs for client-server systems are high. Client applications need to be updated whenever breaking changes are introduced to their servers' APIs. And web services must evolve slowly to maintain backwards compatibility with existing clients. Tightly-coupled client-server systems are rigid and brittle.

The goal of a hypermedia-driven API design would be to facilitate the development of general-purpose client applications that could interact with _any_ service that supports the same hypermedia types. A web service could change its API without breaking client applications. Clients would be pre-programmed to automatically discover the new interface and adapt to it - similar to how web browsers have no problem rendering a website that has just changed its design.

This is not a new idea. In a https://www.scientificamerican.com/article/the-semantic-web/[2001 article in Scientific American magazine], Tim Berners-Lee and colleagues wrote about their vision for semantic web technologies that would enable "intelligent agents" to autonomously discover information and perform tasks on the web, driven by rich semantic descriptions of resources and operations made available by the world's servers.

But, in this blog post, what I'm interested in exploring is this question:

*Could we apply the HATEOAS principle to the design of web service APIs, enough that we could reduce the degree to which client applications are programmed to rigid server interfaces?*

Consider, for example, that modern "single page" webapps tend to be programmed with deep knowledge of their business domain. Domain entities, the relationships between them, and the operations that can be performed on each type, tend to be encoded as much in client application code as they are on the server side. And on the server-side too, in service-oriented systems like microservices, knowledge of subdomains tends to necessarily leak out of the services that are meant to encapsulate that knowledge. Services are never truly "discoverable" in an entirely automated way.

Can we improve this by taking the principle of HATEOAS from web GUIs (human interfaces) to web APIs (machine interfaces)?

== Hypermedia types

First, to realize hypermedia APIs, we need a media type that supports semantics rich enough to _drive_ the behavior of client applications.

What would that look like?

As a minimum, we would need to encode in server response messages all the resources and operations available for clients to explore. A web service provider could invent their own proprietary data schema for this purpose. A simple example might look something like this:

.Request
[source,http]
----
GET /
Accept: application/vnd.api.example.com+json
----

.Response
[source,http]
----
200 OK
Content-Type: application/vnd.api.example.com+json
{
  "links": [
    {
      "href": "/user",
      "rel": "list",
      "method": "GET"
    },
    {
      "href": "/user",
      "rel": "create",
      "method": "POST"
    }
  ]
}
----

Client applications could use this information to dynamically render an interface that presents the user with the listed available. The user may choose the "List users" option. So the client makes a new request...

.Request
[source,html]
----
GET /user
Accept: application/vnd.api.example.com+json
----

.Response
[source,html]
----
200 OK
Content-Type: application/vnd.api.example.com+json
{
  "users": [
    {
      "id": 1,
      "name": "Emil",
      "country: "Sweden",
      "links": [
        {
          "href": "/user/1",
          "rel": "self",
          "method": "GET"
        },
        {
          "href": "/user/1",
          "rel": "edit",
          "method": "PUT"
        },
        {
          "href": "/user/1",
          "rel": "delete",
          "method": "DELETE"
        }
      ]
    },
    {
      "id": 2,
      "name": "Adam",
      "country: "Scotland",
      "links": [
        {
          "href": "/user/2",
          "rel": "self",
          "method": "GET"
        },
        {
          "href": "/user/2",
          "rel": "edit",
          "method": "PUT"
        },
        {
          "href": "/user/2",
          "rel": "delete",
          "method": "DELETE"
        }
      ]
    }
  ]
}
----

What we're trying to do here is develop a custom schema that allows the server to provide machine-parsable descriptions of all the server's available resources and operations. Client applications will required hard-coded knowledge of that schema, but not the server's resources and operations themselves.

The hypermedia controls are defined here as a combination of URI plus HTTP method, while the `rel` attribute uses a common vocabulary – "self", "edit", "delete", etc. – to bring semantic meaning to each control.

But a true hypermedia API would need an even more complex schema than this. For example, in the context of create and edit operations, the server would need to define all the fields, and the acceptable data types and ranges for each, that the client would be required to submit with the operation. For client applications to be truly "driven" by the server, there must be no out-of-band information driving the client's behavior.

Ideally, we'd have a standard hypermedia format for machine interfaces, in the same way that HTML gives us a hypermedia format for human interfaces. This way we will be able to gave generic client applications for all hypermedia APIs that adopt the same standard media types. Above is a proprietary format, shared between a single client-server system. But the true power of hypermedia APIs would come when they can be consumed by generic, dumb clients.





== Linked data




== Hypermedia APIs versus REST APIs

A network API that adhered to the HATEOAS principle would be a _true_ "REST API". As described by Roy Fielding, REST is an architectural style that uses hypermedia as the engine of application state. Thus, as Fielding explained in a https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven[2008 blog post], a true REST API "must be hypertext-driven":

[quote, Roy Fielding]
____
A REST API should spend almost all of its descriptive effort in defining the media type(s) used for representing resources and driving application state, or in defining extended relation names and/or hypertext-enabled markup for existing standard media types.
____

Unfortunately the term "REST API" has suffered from https://martinfowler.com/bliki/SemanticDiffusion.html[semantic diffusion] over the decades. Today, the term "REST API" is widely used as a synonym for any resource-oriented HTTP API. I https://kieranpotts.com/rethinking-rest[wrote about this in 2021], and in that post I suggested we should adopt a new term, "hypermedia API", to describe any API that adheres to the HATEOAS principle (and which may or may not use HTTP as its transport protocol).

////

## Hypermedia types

REST clients hit an initial "root" endpoint and uses the server-provided links to dynamically discover available actions and access the resources it needs. The client need not have prior knowledge of the service or the different steps involved in a workflow. Additionally, the client no longer has to hard-code the URI structures for various resources. The server is thus free to make URI changes as the API evolves, without breaking clients. Version numbering becomes less of a concern.

As far as I can see, in 2021 there are no real-world web service APIs that are truly RESTful — that is, their state fully driven by hypermedia controls embedded in server response messages. Even though there are many web services that are marketed as having "REST APIs", the truth is none of them are true hypermedia APIs.

... In modern "single page" webapps, the client app has knowledge of the business domain — the types of entities, the relationships between them, and the operations that can be performed on each type of resource. By contrast, in truly RESTful, hypermedia-driven APIs, clients would only have knowledge of a media type — some standard for defining and describing linked data and hypermedia controls. The client would never know if a resource represented a person, organization, location, device...

This has not stopped some people trying to bring hypermedia controls to the APIs of web services. There have been valiant attempt to bring the HATEOAS concept — using hypermedia controls, embedded in server response messages, as the main control mechanism by which client's mutate their state — to the APIs of web services.

The most promising standards are JSON-LD and Hydra.

Introducing hypermedia to the programmatic interfaces of web service is an enticing prospect. In theory, it would make web service fully discoverable at runtime, doing away with the need for interface definition documentation. All the knowledge necessary to navigate a hypermedia API would be provided within the response messages of the server.

Thus, client application developers would not need to reference documentation on an API's available resources and types, or the operations that can be performed on them. ... Actually, a hypermedia API would not have "typed" resources that are significant to client applications. Rather, the available resources, and the operations that can be performed on them, would be self-documenting within the server's response messages.

The only out-of-band documentation that a truly RESTful API should require would be descriptions of the media types it uses to represent its resources, and some standard markup system for describing link relations. These things are generic concerns, not specific to the business domain of any particular web service.

This architectural design has the effect of further decoupling clients from servers. Client applications require less hard-coding of the details of the server's API, since the server effectively provides clients with API documentation dynamically at runtime. Cool, eh?

Think of it in terms of the Web. How many Web browsers are aware of the distinction between an online-banking resource and a Wiki resource? None of them. They don't need to be aware of the resource types. What they need to be aware of is the potential state transitions — the link and forms — and what semantics/actions are implied by traversing those links. A browser represents them as distinct UI controls so that a user can see potential transitions and anticipate the effect of chosen actions....

Typed relations, specific media types, and action-specific elements provide the guidance needed for automated agents [such as spiders].

Automated agents are dependent on their understanding of the media types, link types, or microformat extensions provided in representations. It is the same basic issue as with human communication: we will always need a common vocabulary to make sense of it. Exposing that vocabulary in a representation makes it easy to learn and be adopted by others. Some of it will be standardized, some of it will be domain-specific, but ultimately the agents will have to be adaptable to new vocabulary.

Thus, hypermedia APIs could be consumed by generic clients. We would not need to code client applications with so much business domain knowledge hard-coded into them. Some people would call them "smart clients", but really they're dumb clients, in the same way that web browsers are dumb clients.

## Hypermedia types

What media types can we use to realize hypermedia APIs?

> Hypermedia Types are MIME types that contain native hyper-linking semantics that induce application flow.
>
> — Mike Amundsen (2010)

HTML is a hypermedia type. ... There are thousands of IANA registered media types, but very few support hypermedia controls.

The data format of a representation is known as a media type. Some media types are intended for automated processing, some are intended to be rendered for viewing by a user, and a few are capable of both.

General-purpose data interchange formats like JSON and XML on their own don't cut it, because they offer no convention for embedding linked data or defining hypermedia controls.

We need a media type that supports this.

Some standardization is on its way.

== HAL

One of the simplest conventions for embedding linked relations in JSON documents is the Hypermedia Application Language, HAL.

HAL started out as a [personal project](https://stateless.group/hal_specification.html) but its JSON variant is now on a [standardization track](https://datatracker.ietf.org/doc/html/draft-kelly-json-hal-08). Although development of the standard seems to have stalled since about 2016, HAL has achieved a good level of adoption in the real world. Both [Amazon](https://docs.aws.amazon.com/apigateway/api-reference/) and [Netflix](https://netflix.github.io/genie/docs/3.0.0/rest/#_hateoas) have made use of it. And there's an impressive choice of ready-made [client libraries](https://github.com/mikekelly/hal_specification/wiki/Libraries) to aid consumer applications. It's even supported out-of-the-box by Java's [Spring framework](https://spring.io/projects/spring-hateoas#samples).

The simplicity of HAL is surely key to its popularity. And the fact it can be fairly easily retrofitted to many existing APIs. Consider the following example:

```json
{
  "id": "cc8d644b-62d9-45a1-8b60-ea2a6173e0d1",
  "isbn": "9780091906818"
  "title": "How to Win Friends and Influence People",
  "author": "Dale Carnegie"
}
```

In the context of the payload of a response message from a web service API, the properties of this JSON object would represent the _state of a resource_. Since this is a plain JSON object, the declared `Content-Type` would be `application/json`.

To transform this to HAL, all you'd need to do is add two reserved properties, `_links` and (optionally) `_embedded`, and change the media type to `application/hal+json`.

```json
{
  "id": "cc8d644b-62d9-45a1-8b60-ea2a6173e0d1",
  "isbn": "9780091906818"
  "title": "How to Win Friends and Influence People",
  "author": "Dale Carnegie",
  "_links": {},
  "_embedded": {}
}
```

The two new properties are used to define links, the relationships between them, and how the linked resources can be interacted with. "Embedded" links are resources from which the current resource is composed, which is particularly handy for collections.

As an absolute minimum, a HAL-formatted response message will contain an empty resource and a reference to itself.

```json
{
  "_links": {
    "self": {
      "href": "/path/to/resource"
    }
  }
}
```

The names of the top-level properties of the `_links` object are link relations, aka `rel` attributes. This attribute indicates the semantics of the link. Any standard link relation is supported.

```json
{
  "_links": {
    "self": {
      "href": "https://api.example.com/docs/relations/"
    },
    "clients": {
      "href": "https://api.example.com/docs/relations/clients"
    },
    "projects": {
      "href": "https://api.example.com/docs/relations/projects"
    },
    "tasks": {
      "href": "https://api.example.com/docs/relations/tasks"
    }
  }
}
```

HAL supports [CURIE](https://www.w3.org/TR/2007/WD-curie-20070307/) notation for compacting and removing duplication across URIs.

```json
{
  "_links": {
    "self": {
      "href": "/"
    },
    "curies": [
      {
        "name": "doc",
        "href": "https://api.example.com/docs/relations/{rel}",
        "templated": true
      }
    ],
    "doc:clients": {
      "href": "/clients"
    },
    "doc:projects": {
      "href": "/projects"
    },
    "doc:tasks": {
      "href": "/tasks"
    }
  }
}
```

In HAL, the linked resources are not resources of the actual API, rather they are links to human-readable documentation about the API's available resources and operations. In this example, a `GET` request to `https://api.example.com/docs/relations/clients` should return a webpage (or some other human-readable documentation format) containing comprehensive information about all the endpoints related to the "clients" relation type.

It's not a requirement of HAL, but the intention here would be to use an industry standard for defining the links themselves. [RFC 5988](https://tools.ietf.org/html/rfc5988) fits the bill. It puts forward a framework for building links that not only define targets, but also define the relationships between linked resources (`rel`) and other attributes.

That's it for HAL. That's pretty much all it does. [Collection+JSON](http://amundsen.com/media-types/collection/) and [Siren](https://github.com/kevinswiber/siren) are similar solutions with a little more functionality. All these media types offer the same basic ingredients for discoverable APIs: a single entry point that reveals documentation on all the available endpoints.

Although HAL claims to allow "automated actors" to move through an API, it does not live up to this promise. HAL works perfectly well as in-band documentation for the developers of client applications, offering an alternative to OpenAPI and other static documentation conventions. But it does not offer anywhere near the level of semantic information required for an API to be understood by machines.

## JSON Hyper-Schema

[JSON Hyper-Schema](http://json-schema.org/draft/2019-09/json-schema-hypermedia.html) is another lightweight solution for embedding linked data in JSON-encoded payloads.

JSON Hyper-Schema is an extension to [JSON Schema](https://json-schema.org). A JSON Schema document is itself a simple JSON document, but it exists to define the structure, content and (to some extent) semantics of other JSON documents. It is a really well-designed schema standard. As of early 2021, JSON Schema remains a draft specification but it is on a path to full standardisation via the IETF. It has already become the de facto standard for JSON data definition and validation, having gained widespread adoption. For example, it is used in [Google's API Discovery Service](https://developers.google.com/discovery), and the OpenAPI Specification adopts an "extended subset" of [JSON Schema](http://spec.openapis.org/oas/v3.0.3) to provide definitions for web service APIs. For a great usage example, take a look at the sample code for the [Vega data visualisation library](https://vega.github.io/vega/examples/bar-chart/), which uses JSON Schema to define the data objects the library requires for input.

JSON Hyper-Schema extends JSON Schema with [IETF URI templates](https://tools.ietf.org/html/rfc6570), so offering a lightweight solution to embedding linked data.

Continue with examples of JSON Hyper-Schema...

Explain why JSON Hyper-Schema is limited... It's less informal and more robust and capable than HAL. Like HAL, its intended to be an optional progressive enhancement to client applications that expect plain JSON.

## RDF and JSON-LD

The [Resource Description Framework (RDF)](http://www.w3.org/RDF/) is the cornerstone of the "semantic web", a family of specifications from the W3C.

RDF dates all the way back to 1996, with RDF 1.0 being finalised in 2004 and the current RDF 1.1 specification in 2014. This is a mature, stable standard. But the best thing about RDF is its versatility. It is not tied to any particular syntax notation or data serialisation format, and for this reason RDF semantics can be embedded in all sorts of digital media.

So, there's no reason why it can't be ported to the APIs of web services. After all, it is explicitly intended to allow for the exchange of machine-readable information via the web.

The RDF data model is based on the idea of making statements about resources. This is done in expressions in the form of subject-predicate-object. These expressions are known as triples. The subject is the resource, while the predicate denotes a trait or aspect of the resource that forms a relationship between it and the object.

RDF can be used to define data models. Rather than the traditional entity-based approach to data modelling, RDF models are represented as a series of facts. Each fact consists of three parts: a subject, predicate, and object. Because RDF facts always have three parts to them, they are known as triples. The triple is the building block of any RDF data model.

Triples can express properties of resource or express relationships (links) between resources. The result is a graph-based model where resources (subject and object) represent the nodes of the graph and links (predicates) represent the edges of the graph.

RDF data components are usually identified using [URIs](https://www.w3.org/Addressing/). Although they looks like web addresses, they may not necessarily represent an actual webpage.

```
http://www.foaf.com/Person#JoeBloggs
http://www.allmovie.com/Actor#JoeBloggs
```

Helpfully, RDF is not tied to any particular syntax notation or data serialisation format, and for this reason RDF semantics can be embedded in all sorts of digital media. However, there are a number of serialisation formats that are custom-made for RDF data. RDF serialisation formats include Turtle, N-Triples, N-Quads, JSON-LD, Notation3 (or N3), and RDF/XML and RDF/JSON.

RDF serialization standards define a number of formats for representing RDF content for the purpose of storage or exchange with other systems. RDF supports a broad range of serialization formats, including RDF/XML, Turtle, N-Triples, JSON-LD, and others.

The one that is most interesting in the context of hypermedia APIs is **JSON-LD**.

[JSON-LD](https://json-ld.org/), which is a W3C standard, is another system for representing linked data in JSON documents. It is design around the concept of a "context", allowing for mappings to an RDF model, so JSON-LD can also be described as an RDF serialisation format.

Where JSON-LD trumps HAL and JSON Hyper-Schema is in the way it can be extended with vocabularies — or ontologies — such as `schema.org/{type}` to tell us what kind of data we are linking to, giving more semantics to the data. For this reason alone, JSON-LD is capable of being extended to more use cases than HAL and JSON Hyper-Schema. It is for this reason that it is emerging as the conventional media type for hypermedia APIs.... it is emerging as the most popular solution to embedding hypermedia information in web service APIs that share lots of linked data, such as Gmail's API.

Clients who know the JSON-LD data schema can automatically discover and follow those links without any other knowledge — out-of-band documentation about each particular API. This concept is known as "following your nose". Automated agents can follow their noses at runtime, discovering more available hypermedia controls as they traverse through them.

One of the major ideas behind RDF is that serialisation formats – including JSON-LD – support mapping of values to standardised types, per a common vocabulary like [schema.org](https://schema.org/), instead of arbitrary keys. As long as the client is familiar with the vocabulary, they can ascertain meaning from the serialized data without reference to external documentation.

But... Both HAL and JSON-LD are solutions for **linked data**, ie embedding in API responses links to related resources and operations. On their own, these standards are not enough for full automation of clients. For that, hypermedia controls are required to be the primary mechanism to drive a client application's state.

## Schema.org

TODO: Provide an example of a typical JSON object with standard English language key names. Explain this means nothing to machines!

A key component of any hypermedia API will be a **shared, well-defined vocabulary** that both the providers of APIs and the consumers of those APIs understand. If they talk the same language, they can understand each other.

In hypermedia APIs, the choice of vocabulary is a far bigger consideration than traditional HTTP API concerns, like URL structure. The consumer is king. APIs must be optimised for consumers, not providers. From this perspective, things like URL structures are actually not particularly important. Good URL structures are important from the provider's point of view (they aid maintainability, extensibility, etc.), but actually they don't make much difference to how consumers use APIs.

Schema.org is one of the go-to vocabularies... Schema.org is a vocabulary representing common data structures and their relations. Schema.org can be exposed as [JSON-LD](https://en.wikipedia.org/wiki/JSON-LD), [microdata](https://en.wikipedia.org/wiki/Microdata_(HTML)) and [RDFa](https://en.wikipedia.org/wiki/RDFa). Extracting semantical data exposed in the Schema.org vocabulary is supported by a growing number of companies including Google (Search, Gmail), Yahoo!, Bing and Yandex... so if you build an API with schema.org vocabulary, these search engines will immediately understand your data.

Data models provided by Schema.org are popular and were proven efficient. They cover a broad spectrum of topics including creative works, e-commerce, events, medicine, social networking, people, postal addresses, organization data, places or reviews. Schema.org has its root in a ton of pre-existing well designed vocabularies and is successfully used by more and more websites and applications.

Pick schemas applicable to your application, generate your PHP model, then customize and specialize it to fit your needs.

Adding Schema.org markup to websites and apps increases their ranking in search engines results and enables awesome features such as [Google Rich Snippets](https://support.google.com/webmasters/answer/99170?hl=en) and [Gmail markup](https://developers.google.com/gmail/markup/overview).

Mapping your app data model to Schema.org structures can be tedious. When using the generator, your data model will be derived from Schema.org. Adding microdata markup to your templates or serializing your data as JSON-LD will not require specific mapping nor adaptation. It's a matter of minutes.

In Schema.org, the names of things are URIs, rather than conventional strings. In simple terms, Schema.org is just a big collection of URIs.

Schema.org and Hydra are examples of linked data vocabularies. Schema.org is a domain-specific vocab. Other [linked data vocabs](http://lov.okfn.org/dataset/lov/) are available.

For example, when a client wants to send an order to a webshop, then it has to check the hyperlinks in the responses sent by the webshop. By checking the links it finds one described with [http://schema.org/OrderAction](http://schema.org/OrderAction). The client application knows the schema.org vocab, so it understands that by activating this hyperlink it will send the order.

In the context of hypermedia, wouldn't it be nice if there was a standard vocabulary for defining the purpose of every link? JSON-LD doesn't offer such a vocabulary itself, but it can be extended with Hydra which does just that.

- [Schema.org](https://schema.org/) \  A collaboration between Google, Yahoo, Microsoft and Yandex to create, maintain and promote shared schemas for structured data. [Wikipedia entry.](https://en.wikipedia.org/wiki/Schema.org)

- [Dublin Core](http://dublincore.org/) \  The Dublin Core, also known as the Dublin Core Metadata Element Set, is a set of fifteen "core" elements (properties) for describing resources. It was originally developed around the same time the W3C was working on its generic data model for metadata, which became the Resource Description Framework. Dublin Core became one of the most popular vocabularies to use with RDF, more recently in the context of the linked data movement. Here are some encoding examples from Wikipedia:

```  <meta name="DC.Format" content="video/mpeg; 10 minutes" />  <meta name="DC.Language" content="en" />  <meta name="DC.Publisher" content="publisher-name" />  <meta name="DC.Title" content="HYP" />  ```
```
{
  "@context": {
    "@vocab": "http://schema.org/"
  },
  "@id": "...",
}
```

## Hydra

Schema.org improves the interoperability of your applications. Used with hypermedia technologies such as [Hydra](http://www.hydra-cg.com/) it's a big step towards the semantic and machine readable web. It opens the way to generic web API clients able to extract and process data from any website or app using such technologies.

Hydra is a [vocabulary](http://www.hydra-cg.com/spec/latest/core/) that extends JSON-LD to _describe_ linked data. Hydra vocabulary describes what you can do with individual hypermedia links. The Hydra Core Vocabulary also provides machine-readable documentation functionality; for example, it can be used to specify the entry point to an API, as well as all its possible response statuses.    The objective of this standard is to finally realise true hypermedia-driven web APIs, in which smart client dynamically discover and _understand_ resources at runtime, with minimal hard-coded knowledge of the API. It's ambitious!

```json
{
  "@context": [
    {
      "@vocab": "http://schema.org/"
    },
    "http://www.w3.org/ns/hydra/core"
  ],
  "@id": "http://schema.org/attendees",
  "supportedOperation": {
    "@type": "AddAction",
    "method": "POST",
    "expects": {
      "@id": "Person",
      "supportedProperty": {
        "property": "name",
        "required": true
      }
    }
  }
}
```

## RDF Schema and OWL

The Web Ontology Language (OWL) extends RDF with additional schema elements that support more extensive knowledge management. Ontologies provide a useful abstraction for representing knowledge facts and their relationships. OWL supports class abstractions, class hierarchies, taxonomies, and conceptual models.

- [RDF Schema](https://www.w3.org/TR/rdf-schema/) \  The Semantic Web can be thought of as a series of layers, with RDF providing the base layer. Raw RDF provides a straightforward representation of a triple. It offers only a minimal vocabulary, the most useful one being `rdf:type`.    RDF is extended by **RDF Schema (RDFS)** (with the `rdfs:` prefix), which is further extended by **OWL** (with the `owl:` prefix). RDF, RDFS and OWL are complementary. They are a means of expressing increasingly complex information or knowledge. All of them can be expressed in any RDF serialisation syntax like Turtle or N3.

  RDFS and OWL can be described as **data modelling languages** for RDF data.

  For data that cannot be easily modelled with RDF alone, turn to RDFS for solutions to represent more complex relations such as subclasses, with constructs such as `rdfs:subClassOf`.

- [Web Ontology Language (OWL)](https://www.w3.org/TR/owl-ref/) \  OWL offers the highest level of expressivity of triple data. OWL makes it possible to express complex constructs such as chained properties, and restrictions or constraints between classes.

  OWL is a superset of RDFS. For example, `owl:class` is actually a subclass of `rdfs:class`.

  But the primary purpose of OWL is to provide a base for the building of _ontologies_ on top of RDF datasets. Without OWL, RDF would have no ontological capability. With OWL, you can create your own custom schema that describes the data in your web application.

  OWL is thus the basis for many [ontologies](./ontologies.md) that describe various content and data published on the web. For example, the [BBC's ontology](https://www.bbc.co.uk/ontologies) extends from OWL.

  There are several subsets and supersets of OWL, known as "profiles". OWL 1 specified OWL Lite (a subset), OWL Full, and OWL DL (a superset). OWL 2 is itself a superset of OWL 1, and adds the OWL 2 EL, OWL 2 QL and OWL 2 RL profiles. And there's a whole family of profiles that extend from OWL2 QL.

- [SKOS](https://www.w3.org/2004/02/skos/) \  SKOS (Simple Knowledge Organization System) is another W3C "Semantic Web" standard and is also based on RDF and RDFS.    The main objective of SKOS is to be able to bring legacy schemes – such as thesauri, classification schemes, and taxonomies – into semantic web applications using linked data.    SKOS is designed specifically to express information that is more hierarchical: broader terms, narrower terms, preferred terms, and other thesaurus-like relationships.     SKOS is simpler than OWL, and can be extendable into OWL if needed.

## Pie in the sky?

Realising true hypermedia APIs remains a niche speciality and is nowhere near mainstream at this time. ... And it's going to be a difficult problem to solve. Indeed, the REST constraints of HATEOAS and code-on-demand fit particularly awkwardly with modern web service APIs. The requirements of web clients do not lend themselves well to these things. The preference of user experience designers is to provide specialist interfaces for different resources and operations, and this requirement lends itself to the model-driven architecture of modern "single page" web client applications. And shipping code-on-demand is a well-known security risk. And you can't easily do offline-first apps if state transitions require a connection.

Think of it in terms of the Web. How many Web browsers are aware of the distinction between an online banking resource and a Wiki resource? None of them. They don't need to be aware of the resource types. What they need to be aware of is the potential state transitions — the links and forms — and what semantics/actions are implied by traversing those links. A browser represents them as distinct UI controls so the user can see potential transitions and anticipate the effect of chosen actions. A spider can follow them to the extent that the relationships are known to be safe. Typed relations, specific media types, and action-specific elements provide the guidance needed for automated agents.

Automated agents are dependent on their understanding of the media types, link types, or microformat extensions provided in representations. It is the same basic issue as with human communication: we will always need a common vocabulary to make sense of it. Exposing that vocabulary in representations makes it easy to learn and be adopted by others. Some of it will be standardized, some of it will be domain-specific, but ultimately the agents will have to be adaptable to new vocabulary.

The tell-tale sign is the documentation. If a web service provides static documentation for its resources and types, endpoints and operations... then it's API can't possibly be RESTful! A REST API should never have “typed” resources that are significant to the client. Rather, these things would be self-documenting within the server's response messages. The only out-of-band documentation that a truly RESTful API should require would be descriptions of the media types it uses to represent its resources, and some standard markup system for describing link relations — these things are generic concerns, not specific to the business domain of the web service.

> A REST API should be entered with no prior knowledge beyond the initial URI (bookmark) and set of standardized media types that are appropriate for the intended audience... From that point on, all application state transitions must be driven by client selection of server-provided choices that are present in the received representations...
>
> — Roy Fielding

## Model-driven webapps

For this reason, I think hypermedia APIs will not replace existing web service API protocols, like plain HTTP, SOAP, OData, GraphQL, and so on. Rather, hypermedia APIs will open up entirely new use cases that did not exist before.

If you are the only consumer of the API – if you are building a single-page web application, or the API is otherwise only for internal use – then you almost certainly don't need a hypermedia-driven web service, because you've only got one client.

Hypermedia APIs come into their own when:

1. You've got lots of clients, owned by third parties.

2. Those clients are predominantly other computer programs, rather than humans.

3. When the end users don't want to do too much work to use your API, for example integrate your SDKs or otherwise write lots of boilerplate code to write a client to your contract.

4. Arguably, hypermedia APIs are more useful or fully public APIs (no authentication required) rather than private one (where clients must be authenticated before the resources are made available).

So if you want to provide an API that can be used across the web, is as general as possible so it is as easy to consume as possible, as that is as stable and enduring as it can be, then you should invest more time in the design of your API, and you should seriously consider — if not full-blown hypermedia — then at least some aspects of hypermedia.

All server-rendered websites follow this model. But it has not been adopted by modern "single page" web applications.

Webapps tend to be implemented with a model-driven architecture. Application state is controlled within the client itself, with its interface responding to changes in the state of a local data model. Optionally, that local data model may be persisted upstream via a web service API. The server may also update the local data model —	using HTTP/2 Server Push, say — but the server does not tend to drive changes in application state. Instead, all the available server-side resources and operations are hard-coded into the client.

The model-driven architecture brings numerous advantages. The graphical user interfaces of client applications can be made to be highly responsive to user input, since round trips to the server can be eliminated for many operations. And many webapps are freed to operate offline for extended periods of time.

_It follows that most web service APIs tend to be designed around a fairly conventional resource-based architecture with CRUD-like operations. This architectural style for the APIs of the remote services that back modern client applications is a natural fit for the model-driven architecture of those clients._

Although many web services APIs claim to be RESTful, I have yet to find a single real-world API that conforms to the REST constrains of using hypermedia as the engine of application state (HATEOAS).

But wouldn't it be cool if web services could be hypermedia-driven in the same way websites are?

## Conclusions

By this definition, "hypermedia API" is a pretty niche concept. I've seen production APIs that integrate linked data — the "REST API" to [Amazon's API Gateway](https://docs.aws.amazon.com/apigateway/api-reference/), for example, embeds linked data in the [Hypertext Application Language (HAL)](https://datatracker.ietf.org/doc/html/draft-kelly-json-hal-08) — but I have yet to see a real-world example of an API that also adopts a standardised vocabulary such as [Hydra Core](http://www.hydra-cg.com/spec/latest/core/) to describe its linked data. Without these two components — a linked data model defined using a standard vocabulary — an API cannot be fully RESTful. Linked data alone is not enough, because a client application would still require some knowledge of the API's data model to navigate the linked resources and operations.

TODO: If authentic hypermedia APIs actually existed, we would already have generic webapps that can be configured to consume any hypermedia API. We do have some (rather bugger) demo apps [link], but nothing in the real-world yet.

As of 2021, authentic hypermedia APIs have yet to be realised. This remains a largely theoretical endeavour, at the leading edge of development of the World Wide Web.

## Further reading

- Markus Lanthaler is a leading authority on building "next generation" hypermedia-driven APIs with JSON-LD and Hydra, having driven development of these standards. He has numerous articles and talks published all over the web. Go to Markus-Lanthaler.com/hydra

- http://www.markus-lanthaler.com/hydra/console/?url=http://www.markus-lanthaler.com/hydra/api-demo/ - A generic console for consuming Hydra-based web service APIs.

- https://www.hydra-cg.com/ The W3C Hydra community group - free to join!

## Reference resources

- https://lov.linkeddata.es/dataset/lov/vocabs?&page=10

- https://medium.com/@andreasreiser94/why-hateoas-is-useless-and-what-that-means-for-rest-a65194471bc8

- https://www.slideshare.net/lanthaler/building-next-generation-web-ap-is-with-jsonld-and-hydra

- https://api-platform.com/docs/schema-generator/

- https://link.springer.com/chapter/10.1007/978-3-662-46641-4_20

- http://www.ws-rest.org/2012/proc/a5-9-verborgh.pdf |
[a5-9-verborgh.pdf](https://github.com/kieranpotts/_website/files/7026144/a5-9-verborgh.pdf)

- http://www.markus-lanthaler.com/research/third-generation-web-apis-bridging-the-gap-between-rest-and-linked-data.pdf |

[Third Generation Web APIs.pdf](https://github.com/kieranpotts/_website/files/7026148/Third.Generation.Web.APIs.pdf)

- https://wiki.uib.no/info310/images/7/7e/Lanthaler2014-LeveragingLinkedDataToBuildHypermediaDrivenWebAPIs-RESTBook.pdf |

[Lanthaler2014-LeveragingLinkedDataToBuildHypermediaDrivenWebAPIs-RESTBook.pdf](https://github.com/kieranpotts/_website/files/7026154/Lanthaler2014-LeveragingLinkedDataToBuildHypermediaDrivenWebAPIs-RESTBook.pdf)

- https://www.youtube.com/watch?v=fJCtaNRxg9M&t=32s

'''''''''''

I’m working on a follow-on blogpost that goes into much more detail about JSON-LD, Hydra, OWL, etc – the building blocks of true hypermedia APIs. In that post I come to a similar conclusion: hypermedia APIs will not replace HTTP APIs, or any other existing API design conventions for that matter. Hypermedia certainly would not bring sufficient added value to the design of proprietary client apps, where existing model-driven architectures fit perfectly well. These apps will not benefit from "discoverability".

But what hypermedia APIs will do is make possible entirely new categories of data service that just don’t exist today. These use cases will be niche. For example, I can imagine hypermedia APIs being very beneficial to the “open data” initiatives of various governments, and other “big data” use cases.

////
