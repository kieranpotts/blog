= The Mythical Man-Month at 50
Kieran Potts, 28 November 2025
:description: Fred Brooks's classic book The Mythical Man-Month was published 50 years ago. It was hugely influential on the then-nascent discipline of software development. How does it stand up today?
:docinfo: shared
:nofooter:

Frederick P Brooks Jr's classic book _The Mythical Man-Month: Essays on Software Engineering_ was published in 1975 – 50 years ago. The book was one of the first published analyses of the challenges of large-scale software development – an emerging field in 1975.

_The Mythical Man-Month_ introduced many ideas and principles that were hugely influential on early practitioners of our craft. But which ideas have withstood half a century of technological change, and which have not?

I got myself a copy of the original 1975 edition and the extended 20th anniversary (1995) edition, which added four new chapters. Here are my thoughts.

== The tar pit

_The Mythical Man-Month_ is really a collection of standalone essays rather than a cohesive thesis. Nevertheless, there are some key themes that run throughout. The most prominent theme is the one introduced in this opening chapter: that the essential challenge of software development is the management of complexity.

Throughout the book, Brooks draws on his own experiences, notably as the manager who oversaw the initial design of IBM's OS/360 operating system. At the time, OS/360 was one of the biggest, most ambitious, most complex software projects ever attempted. At the peak of the project, more than 1,000 people we working on it.

But, Brooks acknowledges, the project was not "wholly successful". The initial release of OS/360, in 1966, was delivered "late, it [used] more memory than planned, the costs were several times the estimate, and [the first version] did not perform very well".

The opening chapter delivers Brooks's sharp post-mortem of the OS/360 project. He concludes that the fundamental reason for the project's difficulties was that the managers had seriously underestimated the overall costs of delivering such a large-scale software system. This happened because the estimates were based solely on the construction of the individual parts of the system. What the managers had not accounted for was: (a) the integration costs of all those components; and (b) the "productization" of the system as a whole.

Brooks estimates that the work of designing the interfaces between all the components of a system, and coordinating their integration and performing incremental integration testing, has the potential to _triple_ the initial cost of coding all the components in isolation. Costs may triple again for all the work that goes into preparing a large-scale software system for distribution as shrink-wrapped software for general use by the public. For the OS/360 project, they had not fully accounted for how much extra rework and testing would be needed to make the system run reliably in "many operating environments, for many sets of data", and for time spent preparing user-facing documentation and other packaging.

In total, building large, general-purpose, shrink-wrapped software products can cost up to nine times more than writing all the code as separate, non-integrated, private libraries. To put it another way, programming effort is a very small amount of the overall cost of delivering a large-scale software system.

Brooks reflects that large-scale software development, like OS/360, is inherently hard. The reality of developing commercial software for a living, Brooks writes, is that there are many "dreary hours of tedious, painstaking labor", often involving analysis of code written by other people who have moved on to other projects already."

50 years later, this all sounds depressingly familiar.

Despite the immense technological advances of the last half-century – in computer hardware, in programming languages and runtime environments, and in tools and automation that support every aspect of software delivery – the core challenges of large-scale software development remain largely the same. Project failures remain commonplace.

The essential challenge of software development remains the management of complexity. Brooks draws the colorful analogy that large-scale software development is like "the mortal struggles of great beasts in the tar pits". This is represented by the book's cover image, a sketch of Charles Knight's 1925 painting that depicts the great mammoths of the Pleistocene struggling to free themselves from the tar pits of Southern California.

// TODO: Cover photos

"Large and small, massive and wiry, team after team has become entangled in the tar," Brooks writes. His thesis is that it is never one problem, but rather a combination of intractable problems, some unexpected, that make it difficult to move complex projects forward. "No one thing seems to cause the difficulty – any particular paw can be pulled away. But the accumulation of simultaneous and interacting factors brings slower and slower motion."

== The mythical man-month

The eponymous second chapter deals with the perennial issue of software projects being reliably delivered much later than estimated. Brooks explores numerous reasons why estimating and scheduling of software projects is so hard. Are they still relevant today?

=== Optimism

The first explanation the author gives for poor project estimations is a bias toward optimism.

Brooks writes that "all programmers are optimists" and he hypothesizes that, because the age distribution of programmers in 1975 was skewed toward younger age groups, and because younger people tend to be more optimistic than the population at large, then software project estimates are particularly prone to being wildly optimistic.

Brooks adds that the very notion that the development of complex software systems can be accurately estimated is flawed. He writes that "the programmer builds from pure thought-stuff" and that, "for the human makers of things, the incompleteness and inconsistencies of our ideas become clear only during implementation. Thus it is that writing, experimentation, 'working out' are essential disciplines for the theoretician."

=== Progress is not always correlated with effort

The second explanation that Brooks provides for poor estimation is the assumption that delivery schedules can be shortened by adding more programmers. Famously, Brooks writes that "adding manpower to a late software project makes it later."

Brooks's central argument for this is that adding people to a late project _increases total effort_. There's extra effort involved in reorganizing the project delivery plan and managing the larger team. Meanwhile, in-flight work streams are disrupted by the "repartitioning" of work. There follows a permanent increase in intercommunication, required to coordinate the development of dependencies and interfaces, and to coordinate integration testing. There's also more time spent training and onboarding new people.

And some programming tasks cannot be parallelized. Some tasks can only be done sequentially, and so cannot be shared between more programmers. If programmers are already optimally allocated to these tasks, adding more programmers will not speed up completion. To illustrate this point, Brooks offers the suitably colorful analogy of child birth:

[quote, Fred Brooks]
____
The bearing of a child takes nine months, no matter how many women are assigned.
____

Brooks coins the term "man-month" to represent one unit of additional manpower (one person working for one month). Because adding resources to a project in the form of extra man-months increases overall effort, it does not necessarily correspond to an increase in the speed of progress. And yet, Brooks writes 50 years ago, this was a widely held belief and a common practice – hence the mythical nature of extra man-month resources!

[quote, Fred Brooks]
____
Men and months are interchangeable commodities only when a task can be partitioned among many workers _with no communication among them_. This is true of reaping wheat or picking cotton; it is not even approximately true of systems programming.
____

Thus, once a schedule is proven to be unrealistic, there may not be anything that can be done to put the project back on track. Adding more people to a project _will_ decrease the productivity of individual team members, and there comes a tipping point where this decrease in productivity more than offsets the overall addition of resources – so delivery speed _slows_ despite the extra manpower.

// TODO: Replicate diagram from page 19.

The more complex the interrelationships between the component parts of the system under construction, the greater this effect. Today, we know this as Brooks's Law.

[quote, Brooks's Law]
____
Adding manpower to a late software project makes it later.
____

=== Regenerative schedule disaster

The third explanation that Brooks provides for poor estimation is what he terms "regressive schedule disaster".

Brooks writes that project progress tends to be poorly monitored, so when it becomes apparent that schedules have slipped, it's usually already too late to do anything about it. It might even be too late to implement effective strategies, like decreasing scope or simplifying the design. The only thing left to try is to throw more people at the problem – which makes matters worse.

In this situation, Brooks says the only recourse is to reschedule the work with the original team members, "un-augmented" by new recruits. This has the effect of delaying completion of the project, but at least overall costs do not needlessly increase through wasted resources.

Better to increase the number of months than then number of men.

=== System testing must be done last

The fourth explanation that Brooks' gives for poor estimations is that system testing and debugging must be done last, due to the sequential nature of the work. Consequently, testing "is usually the most mis-scheduled part of programming" and multiple rounds of testing and debugging can take up to half the overall schedule.

=== Gutless estimating

The fifth and final explanation that Brooks gives for poor estimation of software projects is that we have a tendency to work to schedules dictated by the customer rather than to bravely guess the effort required to deliver a satisfactory product.

Brooks uses the analogy of cooking an omelette. It typically takes a couple of minutes to cook an omelette. But if, after two minutes, the omelette is not set, the customer has two choices: wait, or eat the omelette raw. The chef has a third choice: turn up the heat. But the effect would be to serve a poor quality product – burnt on the outside, and perhaps still raw in the centre.

[quote, From a menu of a New Orleans restaurant]
____
Good cooking takes time. If you are made to wait, it is to serve you better, and to please you.
____

In the delivery of commercial software, we have a tendency to take the third option: to turn up the heat and try to deliver products within the schedules desired by the customers. "False scheduling to match the patron's desired date is much more common in our discipline than elsewhere in engineering."

Brooks contends we should instead have the "courteous stubbornness" of a chef who refuses to serve a dish until it is ready. Construction of good software, like cooking, takes time. Some tasks just cannot be hurried without spoiling the result.

Brooks suggests that the underlying reason for such widespread "gutless estimating" throughout our industry is that we do not have mature models for estimating software work. "It is very difficult," he writes, "to make a vigorous, plausible, and job-risking defense of an estimate that is derived by no quantitative method, supported by little data, and certified chiefly by the hunches of the managers."

''''

Our industry's immaturity in the science of project estimating and scheduling is, 50 years later, an enduring problem.

Even today, project managers routinely believe that adding more people to a late project can solve schedule slippage. I've seen this myself. It's especially commonplace in consultancies and outsourcing firms, where the software house bills its customers in man-hours and therefore has a commercial incentive to add as many people as possible to their projects. But I've seen it in software houses, too – which should know better.

Brooks is most convincing in his argument that the very notion that the development of software can be accurately estimated is deeply flawed. Software development is an inherently complex and unpredictable activity. In every software project, even those with stable and known requirements, there will always be some requirements that are emergent. Requirements may emerge only through design and construction, or even later still, when working software is finally put into the hands of real users. This is the _nature_ of software development, which is more of a design problem than a construction task.

The misplaced belief that the delivery of complex software can be planned in meticulous detail is still a widely held in 2025.

Of course, some things have improved. In the intervening years, our industry has universally adopted iterative and incremental development practices, in which small chunks of work are delivered at regular intervals with testing and debugging done in parallel to the design and construction. Thus, the correctness of the evolving system is continuously evaluated, rather than waiting until the system is complete. The problem of testing being done last, and thus defects in the design being discovered late, has been solved.

I'm not also convinced by Brooks' explanation that poor estimation is a consequence of the relatively young ages of computer programmers. Sure, younger developers lack the necessary experience to do accurate estimates, but in my experience senior developers can be just as guilty of optimism bias. Contingency planning and risk management are still poorly practiced in many software projects today – regardless of who's drawing up the project plans.

I think there are many other explanations why poor estimates persist. There certainly remains a lack of maturity in the methods and tools we use for estimation. Overuse of proxy measures, such as T-shirt sizes and story points, which do not directly correspond to real-world effort, rather than more quantitative data-driven estimation techniques, is commonplace today. Estimations tend to be done very early in the development lifecycle, too. We tend to make estimates base on high-level requirements – even vague and incomplete ones – rather than based on comprehensive, high-fidelity solution designs. If you want good estimates, you need the solution to be sufficiently flesh-out with enough detail to reveal the true scope and complexity of the problem. This is true of every engineering discipline.

Good estimation is done bottom-up from low-level technical designs, rather than top-down from high-level business requirements. But commercial pressures often force estimates to be done from requirements rather than designs. And gutless estimation, in which product manager produce estimates that align with business expectations rather than technical realities, is still very, very common.

// -------------------------------------------------------------------------------------------------

== The surgical team

In the third chapter, Brooks introduces the idea of the *surgical team* as his proposed solution to the problems of large-scale software development.

Brooks observes that many program managers believe they are better off have a small number of very skilled programmers on their team, rather than a large number of mediocre ones.

Brooks argues that large-scale projects should be broken down into smaller subsystems, with each subsystem built by one small, independent team. Each team should operate similarly to a surgical team in a hospital. Each team would have a chief programmer, the surgeon, who is in charge of the whole thing. The rest of the team members try to help him complete the project (the surgery).

The leaders of the surgical teams also collaborate with each other, to coordinate the work on the subsystems so they can be successfully integrated together to compose a complete solution. Thus, communication overhead throughout the overall project is minimized by having a hierarchy of delivery teams, each working on discrete subsystems of the overall solution.

In a surgical team, the whole project is the brainchild of the surgeon. The surgeon is responsible for defining and maintaining the *conceptual integrity* of the solution. By comparison, Brooks writes, in *collaborative teams* everyone is equal and everyone can have input into the direction of the project, even if this sometimes causes chaos.

Brooks quotes research by Sackman, Grant and Erickson that very good professional programmers are _ten times_ as productive as poor ones (at same training and two-year experience level) – this is the origin of the 10x programmer. The author's data showed no correlation between experience and performance, but Brooks doubts the universality of that finding.

// TODO: Conclusion - the analogy of the surgical team is not well remembered, but the principles are widely understood. This principle manifests in job roles like "technical lead" and "solution architect"…

An underlying thesis of the book is that "the brute-force approach is costly, slow, inefficient, and produces systems that are not conceptually integrated", ie. the preference is for small surgical teams  of "first-class people" rather than hundreds of mediocre programmers.

It is why, Brooks concludes, there are many accounts of two programmers working in a garage to build "an important program that surpasses the best efforts of large teams".

The cliché of the garage startup has much deeper roots than I realized!

Most qualified software development managers would agree that the ideal approach to software development is to have a small, sharp team, "which by common consensus shouldn't exceed 10 people", over hundreds of average programmers. ... For efficiency, and conceptual integrity.

But this isn't practical for very large-scale software projects. Brooks notes that the OS/360 project peaked at over 1,000 people working on it concurrently. A smaller 200-man team would have taken 25 years to achieve what was done in just a few years by the larger team. This sort of timescale is just not commercially viable.

The problem with the small team ideal is that it is just too small for really big systems. You just go too slowly.

How can we reconcile the need for considerable manpower, with the desire for efficiency and conceptual integrity?

Brooks cites a proposal by Harlan Mills, titled "Chief programmer teams, principles, and procedures" and published in an IBM report in 1971.

[quote]
____
Mills proposes that each segment of a large job be tackled by a team, but that the team be organized like a surgical team rather than a hog-butchering team. That is, instead of each member cutting away on the problem, one does the cutting and the others give him every support that will enhance his effectiveness and productivity.
____

In this delivery model, the *chief programmer* is like the surgeon. "He personally defines the functional and performance specifications, designs the program, codes it, tests it, and writes its documentation". The chief programmer is supported by a *copilot* who's main function is to contribute to discussions on the design and implementation. The copilot often represents his team in discussions with the chief programmer, and he researches and proposes alternative design strategies for the chief's consideration.

The idea is that "few minds are involved in design and construction, yet many hands are brought to bear".

// Not dissimilar to pair and mob programming...

Other roles include: an *administrator* "who handles money, people, space, and machines"; an *editor* who is responsible for generating the documentation; one *secretary* each to support the administrator and the editor; a *program clerk* who is responsible for "maintaining all the technical records of the team in a programming-product library"; a *toolsmith* who implements any special tools needed by the team, such as for "file-editing, text-editing, and interactive debugging"; and a *tester* who is responsible for "testing the hole thing", preparing suitable test cases from the functional specifications, and devising dummy data for day-to-day debugging.

Mills also proposed that each team be supported by a *language lawyer* who is an expert in the programming language being used, and who provides consultancy to the team in how best to use the language and avoid its common pitfalls.

Today, many of these roles have been automated away or folded into the responsibilities of the computer programmers.

Brooks notes that in a conventional team "the partners divide the work, and each is responsible for the design and implementation of part of the work". But in the surgical team, "the surgeon and copilot are each cognizant of all of the design and all of the code". Brooks argues that this helps to maintain the conceptual integrity of the overall design. In 1975, this approach also offered a work around to more practical constraints, such as the need to allocate storage space and disk access to each individual contributor.

The "lack of division of the problem and the [lack of a] superior-subordinate relationship... make it possible for the surgical team to act _uno animo_".

"Yet the specialization of function of the remainder of the team is the key to its efficiency, for it permits a radically simpler communication pattern among the members." This is perhaps something we have lost. We've tended toward generalization rather than specialization. And yet, any economist would tell you that the path to productivity is via specialization.

Brooks closes this chapter by arguing that it is easier to scale surgical teams because there is less team-to-team communication overhead. You need only to coordinate the work of the chief programmers, who represent a small number of the overall number of programming specialists.

The "entire system also must have conceptual integrity, and that requires a system architect to design it all, from the top down".

// TODO: Bottom-up approach has become prevalent.

== Chapter 4. Conceptual integrity

Brooks defines *conceptual integrity* in chapter four, titled "Aristocracy, Democracy, and System Design". He argues this is probably the most important aspect of large system programming, but one that is often overlooked as programmers have a tendency to focus on the design of individual features rather than the design of the overall system. Brooks argues that large-scale systems should have a consistent design philosophy flow through all subsystems. It is better to have one good idea and carry it through the project, than having several uncoordinated good ideas.

Conceptual integrity can be preserved, Brooks argues, by having one system architect who designs the whole system from top-to-bottom. Brooks argues that the system architect should stick with the design of the system, and not get involved with the implementation. Implementation and design should be treated as two separate phases. A system architect defines the design specifications, while the builders define the implementation specifications. System architecture should be based on user requirements.

Key themes: One is that commercial software development is harder than solo programming because of the *division of labor*. The other main theme is that the *conceptual integrity* of a system is critical to its success.

Brooks's notion of conceptual integrity is, I think, the most important principle of software architecture. It has become part of our industry's lexicon, though today you are more likely to hear terms like "cohesion" and "design consistency".

[quote, Fred Brooks]
____
I will contend that conceptual integrity is _the_ most important consideration in system design. It is better to have a system omit certain anomalous features and improvements, but to reflect one set of ideas, than to have one that contains many good but independent and uncoordinated ideas.
____

// TODO: Define conceptual integrity
// *Conceptual integrity* is a *link:./quality-attributes.adoc[quality attribute]* of a software system. A system with high conceptual integrity is one where all the concepts and their relationships with each other are applied in a consistent way throughout the system. Anywhere you look in the system, you can tell that it is part of an overall design.

// TODO: Why is conceptual integrity important?
// A software system with high conceptual integrity – or high cohesion – tends to be easy to maintain. We can more confidently change part of a system with a cohesive design because we can draw upon our mental map of the architecture and understand intuitively the full repercussions of making the change.

[quote, Fred Brooks]
____
Ease of use, then, dictates unity of design – conceptual integrity.
____

Unfortunately, maintaining conceptual integrity is notoriously difficult as a software system grows in size and scope. To explain why, Brooks draws a parallel with European cathedrals, most of which "show differences in plan or architectural style between parts built in different generations by different builders". In software, Brooks notes, conceptual disunity arises not from the passage of time – hundreds of years separating phases of functional extension – but from the decomposition of the design into "many tasks done by many men".

The necessity to have a *division of labour* in large-scale software projects makes it hard to maintain the conceptual integrity of the overall system design.

// == Conceptual integrity

// // TODO

// // The _ratio_ of function to conceptual complexity is the ultimate test of system design. This ratio is a measure of ease of use.

// Brooks uses a number of examples of computer programming environments to argue that _ease of use_ is derived from a balance being struck between two factors: function and simplicity. "Neither function alone nor simplicity alone defines a good design." A useful system is one that is both rich in functionality and is straightforward to use.  Every part of the system, Brooks argues, should reflect a consistent set of design philosophies and the same balance of competing forces.

// Thus, to achieve ease of use, "the design must proceed from one mind, or from a very small number of agreeing resonated minds" to maintain the necessary conceptual integrity.

// Brooks suggests that the concept of the surgical team, and the division of labour between architecture and implementation, are techniques that help to maintain conceptual integrity of large-scale software systems.

// "The separation of architectural effort from implementation is a very powerful way of getting conceptual integrity on very large projects." Here, Brooks defines the _architecture_ as "the complete and detailed specification of the user interface". The _implementation_ is everything else. Today, we would define architecture more broadly, to include the overall design of the system, including the data model, the interfaces between components, the deployment infrastructure, and so on. Brooks's definition of "architecture" in 1975 we would term "user experience" today. Thus, the distinction between _design_ and _implementation_ is a much murkier one in 2025 than it was in 1975, reflective of the nature of the software systems we build today. Nevertheless, the broad principle remains sound: that one or two key people should oversee the overall design and technical strategy.

// // Discipline is good for art. The external provision of an architecture enhances, not cramps, the creative style of an implementing group.

// // A conceptually integrated system is faster to build and to test.

// The trade-off is that architects become something of an aristocracy, and demographic ideals that help to form cohesive teams are sacrificed. "Are not the architects a new aristocracy, an intellectual elite, set up to tell the poor dumb implementers what to do?" Brooks asks. "Won't one get a better product by getting the good ideas from all the team, following a demographic philosophy…?"

// Brooks argues that there must be a balance between demographic and autocratic approaches to software design. Everyone should be able to contribute ideas to the design, but ultimately there must be a single authority who makes the final decisions. Brooks also makes the point that implementation – the raw coding – is also a form of creative work, just one that operates at a different level of abstraction to the architecture. While the architect has the most influence over the ease of use of the product, the implementers will have the most influence over its performance.

// Brooks says implementers tend to have these three objections to a small architectural team having all the responsibility for the external specifications (ie. the design):

// * The specifications will be too rich in function and will not reflect practical cost considerations. Brooks addresses this in the next chapter.

// * The architects will get all the creative fun and shut out the inventiveness of the implementers. Brooks counteracts: "The opportunity to be creative and inventive in implementation is not significantly diminished by working within a given external specification."

// * The many implementers will have to sit idly by while the specifications come through the narrow funnel that is the architecture team. Brooks argues that this can be resolved easily through timing and phasing. Unlike in the construction industry, in which builders tend not be to be hired until the architectural designs are finalized, the pace is quicker in computing and specification and building therefore tend to overlap. Implementers can start to implement as soon as he has relatively vague assumptions about the requirements; code is easier to change than bricks and mortar and steel. Some time must be spent up-front communicating with the architects, too.

// Brooks says that, besides conceptual integrity, the horizontal division of labour between architecture and implementation also significantly improves communication flows within teams.

// // Much of software architecture, implementation, and realization can proceed in parallel.

// ----------------

// Bottom-up design is an approach to *link:./system-design.adoc[system design]* that emphasizes building systems from small, primitive components, gradually integrating lots of small parts to compose the complete solution. It is sometimes used as a synonym for [evolutionary design], which is a similar concept.

// Bottom-up design contrasts with *link:./top-down-design.adoc[top-down design]*, which instead emphasizes up-front planning and design through [decomposition] of the problem space into lots of subsystems.

// Bottom-up design is often desirable in situations where there are limited resources (such as time or people) or where the requirements are unclear or unstable. The emphasis is on reusing generic components to compose custom solutions with minimal bespoke code. The base components are linked together to form larger subsystems, which are in turn connected to form the complete system.

// The main benefit of bottom-up design is [reusability] of existing code. The main downside of bottom-up design is that is can be overly organic, leading to a tangle of elements and subsystems with no overall structure and limited consistency. Development of large-scale systems especially requires some degree of top-down design to maintain [conceptual integrity]. In practice, most modern software design practices combine elements of both top-down and bottom-up design.

// ////

== Chapter 5. The second-system effect

// The fifth chapter is titled "The second-system effect". Brooks argues that the first system that a programmer designs and builds is often the best, because it is simple and elegant. The second system, however, tends to be over-engineered and bloated with features. Brooks calls this the "second-system effect".

// "The architect has two possible answers when confronted with an estimate that is too high: cut the design or challenge the estimate by suggesting cheaper implementations."

// Brooks calls for "thoroughgoing, careful, and sympathetic communication between architect and builder". The architects should _suggest_, not _dictate_ cheaper implementation strategies. The builder, ultimately, has responsibility for the implementation. This is a two-way conversation. The builder, too, might suggest changes to the architecture – perhaps "some minor feature may have unexpectedly large costs when the implementation is worked out".

// // Deal quietly and privately in ideas put forward by a builder. Be ready to forgo credit for suggested improvements. - This all comes under the banner of emotional intelligence and psychological safety...

// // Early and continuous communication can give the architect good cost readings, and the builder confidence in the design, without blurring the clear division of responsibilities.

// Brooks calls architecture an "interactive discipline".

// Brooks then talks about the second-system effect. What he is talking about here is the tendency for post-MVP (minimum viable product) systems to be increasingly over-engineered and bloated with features. "The general tendency is to over-design the second system [ie. version 2 of a product], using all the ideas and frills that were cautiously sidetracked on the first one." The result is a "big pile". Brooks gives the example of the IBM 709, an upgrade to the IBM 704. While the 704 was "very successful and clean", the 709's "operation set [was] so rich and profuse that only about half of it was regularly used".

// "The second-system effect has another manifestation… a tendency to refine techniques whose very existence has been made obsolete…" Brooks gives examples from the OS/360 project, in which some of the innovations had become obsolete by the time they were finessed in OS/360.

// Brooks suggests that self-discipline is a particularly critical trait for an architect to have in designing the second version of a software product. The architect must "exert extra self-discipline to avoid functional ornamentation and to avoid extrapolation of functions that are obviated by changes in assumptions and purposes".

// Brooks suggests that "each little function" be assigned a value: "capability _x_ is worth not more than _m_ bytes of memory and _n_ microseconds per invocation". Translating such benchmarks from system programming to application programming requires different metrics, but the principle is a good one, and we don't _cost_ our features like this enough.

== Chapter 6. Passing the word

// Chapter six is titled "Passing the word". Brooks argues that the most important thing in software development is communication.

// // How can we resolve this? Brooks asks: "How does on keep the architects from drifting off into the blue with unimplementable or costly specifications?" And: "How does one ensure that every trifling detail of an architectural specification gets communicated to the implementer, properly understood by him, and accurately incorporated into the product?" These questions are as pertinent in 2025 as they were in 1975.

// "How can a group of 10 architects maintain the conceptual integrity of a system which 1000 men are building?" To answer this question, Brooks draws on a communication system worked out for the System/360 design effort – this was a hardware project, but he argues the techniques are equally applicable to software projects.

// There are multiple communication artifacts that need to be created an maintained:

// * *The manual*: This is a written _external_ specification for the system under construction, ie. a user manual. This is the most important artifact products by software architects. "It describes and prescribes every detail of what the user sees" and omit everything that the user does not see – ie. implementation details are excluded and are left to the builders to decide. Feedback from users and implementers helps to refine the design. Changes to the manual are recorded using dated versioning. User manuals might make dull reading, but precision is preferred to liveliness. Manuals should define what is _not_ prescribed as carefully as what _is_ – this is how precision is achieved.

// * *Formal definitions*: Since English, or any other human language, is not naturally _precise_, formal notations should be preferred to define a system's interfaces. Formal notations tend to be both precise and complete. But they lack comprehensibility. Therefore, ultimately you probably want specifications to be formed from a mix of formal notations and descriptions in prose.

// // Once needs both a formal definition of a design, for precision, and a prose definition, for comprehensibility. One of the formal and prose definitions must be standard, and the other derivative; either definition can serve in either role.

// Brooks notes that there are many tools available for formal definitions: the Backus-Naur Form (BNF) for language definition, for example.

// "… an implementation can serve as a formal definition. When the first compatible computers were built, this was exactly the technique used. The new machine was to match an existing machine. The manual was vague on some point? 'Ask the machine!' … A programmed simulator… can serve in precisely the same way." Using an implementation as a definition has some advantages, not least all questions can be unambiguously answered by running tests or experiments to determine the behavior. It also answers lots of questions we might have about how the implementation will need to work to meet the required behavior.

// Proofs of concept / prototypes / mocks.

// But the trade-off is that there can be some confusions as to which is the source-of-truth for the behavior: the reference implementation or the manual? It is particularly important that simulated implementations be carefully maintained for as long as they act as a standard.

// // An implementation, including a simulation, can serve as an architectural definition - but has formidable disadvantages.

// * *Direct incorporation*: "A lovely technique for disseminating and enforcing definitions is available for the software system architect… This technique is to design the declaration of the passed parameters or shared storage, and to require the implementations to include that declaration via a compile-time operation". We uses interfaces, available in most modern programming languages, for this purpose. For distributed systems…

// * *Meetings*: Meetings are necessary. Brooks suggests two levels are useful: a weekly half-day conference of all the architects (decisions from which give quick results and allow work to proceed); and annual supreme court sessions, lasting typically two weeks (in which a built-up backlog of open issues and appeals against prior design decisions are resolved).

// * *Multiple implementations*: If the manual and the system disagree, one can be changed (it is usually easier to change the manual). However, if there is divergence in behavior between multiple implementations, this is harder to resolve. Today, we have the concept of a single source-of-truth, usually a reference code repository from which all implementation instances are compiled.

// * The *telephone log*: This is maintained by the architects and it records every question and every answer between implementers and the architects. No matter how precise the specification, there will always be clarifications needed, and these must be communicated with everyone. Such mechanisms can be quite informal…

// * *Product test*: An independent product testing organization checks the system against specifications, and serves as a devil's advocate, pinpointing every conceivable defect and discrepancy. "Every development organization needs such an independent technical auditing group to keep it honest." … "In the last analysis the customer is the independent auditor. In the merciless light of real use, every flaw will show. The product-testing group then is the surrogate customer, specialized for finding flaws." (Brooks calls the product-testing organization the "daily adversary", but also the "best friend", of the project manager.

// Testing, then, is a critical piece of "passing the word" between architect and implementer. The role of the tester, ultimately, is to find "where the design decisions were not properly understood or accurately implemented". This link must operate "early and simultaneously" with design.

== Chapter 7. The Tower of Babel

// // Chapter seven, titled "Why did the Tower of Babel fail?" is another important chapter in the book. Brooks uses the biblical story of the Tower of Babel as a metaphor for the communication breakdowns that can occur in large software projects. Originally, the people of Babel spoke the same language and they were all united. Babel fell when the people started speaking different languages and could no longer communicate with each other. The Tower of Babel failed not because of technological limitations or a lack of resources, but because of communication problems and the disorganization that resulted from them.

// // The same thing is the cause of many failures in the delivery of large computer systems, Brooks argues. To improve communication within a large project, Brook suggests keeping a *workbook* for the project. The workbook contains all the documentation relevant to the project, from high-level missions and objectives, via external specifications (what we would now call user acceptance criteria), to internal specifications and design documents. Critically, the workbook must also record the changes made to the project over time. Changes to the contents of the workbook should also be recorded.

// // As the workbook increases in size, it become more important to impose a strict structure to its contents. Indexing and numbering systems may be used to help people find the information they're looking for.

// The seventh chapter is titled "Why did the Tower of Babel fall?". Brooks uses the biblical story of the Tower of Babel to illustrate the problems that arise when a large number of people are working on a project without a common language.

// This chapter is all about the importance of communication.

// The Tower of Babel is a myth from the Book of Genesis that is meant to explain the existence of different languages and cultures around the world. According to the story, a united human race with a common language agree to build a great city with a mighty tower. Noticing humanity's power in unity and through common language, God confounds their speech so that the people can no longer communicate effectively with one another. The people fail to complete the engineering work, and scatter around the Earth, leaving Babel unfinished.

// Brooks calls the tower of Babel "the first engineering fiasco" – but not the last. The project failed, not because of lack of manpower, materials, time, or knowledge, but because the collaborators failed to communicate effectively with one another, and therefore they could not efficiently coordinate their individual efforts.

// [quote, Fred Brooks]
// ____
// Communication and its consequent, organization, are critical for success. The techniques of communication and organization demand from the manager much thought and as much experienced competence as the software technology itself.
// ____

// // Teams should communicate with one another in as many ways as possible.

// Brooks proposed three techniques for large-scale team communication:

// * *Informal communication*: eg. a clear definition of intergroup dependencies will help to clarify the lines of communication (in those days, by phone).

// * Regular project *meetings*, "with one team after another giving technical briefings, are invaluable. Hundreds of minor misunderstandings get smoked out this way."

// * A project *workbook*, which is a "centralized, up-to-date, and universally accessible repository of all of the project's documentation, including objectives, interface specifications, technical/internal specifications, technical standards, and administrative memoranda. Brooks goes into some length about how the OS/360 project soon ended up with a printed workbook _five inches thick_, with hundreds of pages being reprinted and replaced in a typical day. The project switched to using microfiche, which reduced the costs of maintaining (and constantly reprinting large numbers of copies of) the workbook. Today we'd typically use a wiki system like Confluence at a cost of a few dollars per month per user.

// // Even in 1975, Brooks noted that a "shared electronic notebook" is a much more effective, cheaper, and simpler mechanism.

// *Organization*:

// The purpose of organization is to reduce the amount of communication and coordination necessary.

// Organization embodies _division of labor_ and _specialization of function_ is order to obviate communication.

// The conventional organization tree reflects the _authority_ structure principle that no one person can serve two masters. But the _communication_ structure in an organization is actually a network, not a tree-like structure, so all kinds of special organization mechanisms ("dotted lines") have to be devised to overcome the communication deficiencies of the tree-structured organization – staff groups, task forces, committees, etc.

// Within a tree-like hierarchy, each subtree must have the following components to be effective:

// * A mission
// * A producer
// * An architect or technical director
// * A schedule
// * A division of labor
// * Interface definitions among the parts

// There are two key leadership roles:

// * The *producer* (this role would be called the "project manager" or perhaps "product manager" today) is responsible for the overall project and its success. The producer is responsible for the schedule, assembling the team, acquiring resources. Communicates upwards and outwards.

// * *The *architect* or *technical director*. Conceives the design of the product, and specifies how it will look from the outside, and also sketches its internal structure. He provides unity and conceptual integrity to the whole design; thus he serves as a limit on system complexity. His communication is chiefly within the teams and is almost completely technical. (Domain knowledge also important - this is not something Brooks covers.)

// The functions of the two roles are quite distinct and require different talents. However, depending on the talents of the people involved, these two roles could be fulfilled by one person, or one might be the boss and the other the boss's right-hand man (copilot).

== Chapter 8. Calling the shot

// Chapter 8 is all about estimating effort.

Ratios: In an earlier chapter, Brooks suggests that the cost of a large-scale software project breaks down into about: 1/3 of the schedule is for design, 1/6 for coding, 1/4 for component testing, and 1/4 for system testing.

TODO: Do these ratios hold up?

// One cannot accurately estimate the total effort or schedule of a programming project by simply estimating the coding time and multiplying by factors for the other parts of the task.

"The coding is only one-sixth or so of the problem, and errors in its estimate or in the ratios could lead to ridiculous results."

// Data for building small isolated systems are not applicable to programming systems projects -- ie. to large-scale software projects.

"For a program averaging about 3200 words, for example, Sackman, Erikson, and Grant report an average code-plus debug time of about 178 hours for a single programmers, a figure which would extrapolate to give an annual productivity of 35,800 statements per year. A program half that size took less than one-fourth as long, and extrapolated productivity is almost 80,000 statements per year."

The essence of this chapter is that "the linear extrapolation of such sprint figures is meaningless". Brooks gives the analogy that "extrapolation of the times for the hundred-yard dash shows that a man can run a mile in under three minutes".

// Programming increases goes as a power of program size. Some published studies show the exponent to be about 1.5.

// Brooks summarizes data from a variety of sources available at the time: Charles Portman, manager of ICL's software division; Joel Aron, manager of Systems Technology at IBM; John Harr, manager of programming for the Bell Telephone Laboratories' Electronic Switching System; OS/360 data; and others. Various research suggests:

// * Programmers spend only half their time programming and debugging. The other half is on overhead-type tasks.

// * Productivity can vary from 1.5 to 10 KLOC (thousand lines of code) per programmer per year. The more interactions between programmers and system parts, the lower the productivity.

// * Productivity – as measured in lines of code written – also varies significantly by category of software system, eg. between operating systems and compilers.

// * Productivity seems constant in terms of elementary statements, a conclusion that is reasonable in terms of the thought a statement requires and the errors it may include.

// * Programming productivity can be increased as much as five times when a suitable high-level programming language is used.

== Chapter 9. Ten pounds in a five-pound sack

// This chapter is all about using hardware resources efficiently.

// Much of this is no longer relevant, due to advances in hardware and the reduced constraints under which we must design software to operate. For example, Brooks says that memory consumption limits is a crucial decision, because performance is so closely related to the transient area. But even 20 years later, Brooks acknowledges that this decision has been obsoleted, first by virtal memory and then by cheap real memory. Users now buy enough real memory to hold all the code for all of the major applications they run on their system.

// Aside from the running time, the _memory space_ occupied by a program is a principal cost. This is especially true of operating systems, where much is resident (in memory) all the time.

// The software builder should set size targets, control size, and devise size-reduction techniques (just as a hardware builder does for components). Size budgets must be explicit not only about resident size but also about the disk accesses occasioned by program fetches.

// Size budgets must be tied to function assignments; define exactly what a module must do when you specify how big it is allowed to be.

// On large teams, subteams tend to suboptimize to meet their own targets rather than think about the total effect on the user. This is a major hazard for achieving good performance in large-scale systems.

// All during implementation, the system architects must maintain constant vigilance to ensure continued system integrity.

// Fostering a total-system, user-oriented attitude may well be the most important function of the programming manager.

// To make good space-time trade-offs, a team needs to be trained in the programming techniques peculiar to a particular language or machine.

// Every project needs a standard library of components.

// Finally, on technical innovation, Brooks observes that genuinely lean and fast programs are the result of _strategic breakthroughs_, such as a new algorithm, rather than tactical cleverness. And, since *representation is the essence of programming* (ie. how data is stored), redoing the representation of the data or its storage tables will often yield bigger performance improvements than optimizing the business logic.

TODO: Size is still important in many contexts, eg. client-side web applications, embedded software, and operating systems still.

**

*"Representation is the essence of programming."*

"Beyond craftsmanship lies invention, and it is here that lean, spare, fast porgrams are born. Almost always these are the result of strategic breakthrough rather than tactical cleverness. ... [eg. a new algorithm]

"Much more often, strategic breakthrough will come from redoing the representation of the data or tables. This is where the heart of a program lies. Show me your flowcharts and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won't usually need your flowcharts; they'll be obvious."

"The programmer at wit's end for lack of space can often do best by disentangling himself from his code, rearing back, and contemplating his data. Representation _is_ tg=he essence of programming."

== Chapter 10. The documentary hypothesis

"The hypothesis: Amid a wash of paper, a small number of documents become the critical pivots around which every project's management revolves. These are the manager's chief personal tools."

// The hypothesis states that, amid a wash of paper, a small number of documents will become the critical pivots around which every project's management revolves.

// For a computer development project, the critical documents are: the objectives, the specifications (including performance specifications), space allocations (memory), the schedule and budget, the organization chart and floor plan, and the estimate, forecast, and prices of the machine itself.

// For a software project, the needs are the same, except for the hardware costs.

// Even on a small project, the manager should formalize such a set of documents. Preparing each document focuses thought and crystallizes discussion. The act of writing requires hundreds of mini-decisions – resulting in clear, exact policies, rather than fuzzy ones.

// Maintaining each critical document provides a status surveillance and warning mechanism. Each document itself serves as a checklist and a database.

// The project manager's job, fundamentally, is to keep everyone going in the same direction.

// The project manager's chief daily task is communication (hearing, reporting, teaching, exhorting, counseling, encouraging), not decision-making. The documents communicate the plans and decisions to the whole team.

"The task of the manager is to develop a plan and then to realize it. But only the written plan is precise and communicable. Such a plan consists of documents on what, when, how much, where, and who. This small set of critical documents encapsulates much of the manager's work."

== Chapter 11. Plan to throw one away

// // In chapter 11, titled "Plan to Throw One Away", Brooks proposes building *pilot models* or *pilot systems* as an intermediate step between the initial system design and the construction of the final system. The pilot system helps to identify potential problems with the design before the final solution is built. The pilot system should be thrown away and not given to the customer. This is because the pilot model often has bugs in it, which would reduce the customer's confidence in the producer.

Today: prototypes and proofs-of-concepts (POCs).

// Chemical engineers have learned not to take a process from the lab bench to the factory in one step, but to build a _pilot plant_ to give experience in scaling quantities up and operating in non-protective environments.

// This intermediate step is equally necessary for programming products, but software engineers do not yet routinely field-test a pilot system before undertaking to deliver the real product. – By 1995, this had become common practice, with "beta" versions. Brooks also advocates the use of "alpha" versions, which are prototypes with limited functionality.

// Brooks says that, for most projects, the first system built is barely usable: too slow, too big, too hard to use, or all three.

// The discard-and-redesign can be done in a big bang, or incrementally… but _it is inevitable_.

// Delivering the first system, the throwaway, to users will buy time – but perhaps at the cost of agony for the user, distraction for the builders who now have to support the production v1 while doing the redesign for v2, and potentially earn the product a bad reputation that will be hard to live down.

// Both the actual need, and the user's perceptions of their needs, will change as the solutions are built, tested, and used. The tractability and the invisibility of the software product expose its builders (exceptionally) to perpetual changes in requirements. But anyway, some valid changes in objectives (and in development strategies) are inevitable, so it is better to be prepared for them, than to assume changes will not come.

// The techniques for planning a software product for change – especially structured programming with careful module interface documentation – were well known but not widely practiced in 1975. But by 1995, this principle was much more widely embedded in software development practice.

// Brooks suggests using high-level languages, compile-time operations, and self-documenting techniques, to reduce errors introduced by change. (Automated testing is not mentioned.)

// Quantify changes into well-defined numbered versions – by 1995 this was standard practice, and today version control are standard tools.

// // TODO: Proofs-of-concept (POCs) meet this principle.

// Brooks writes:

// [quote]
// ____
// Plan to throw one away; you will, anyhow.
// ____

// Brooks was using the metaphor of letter writing, suggesting that successful software development depends a great deal on trial and error.

// But it is an economic reality that we must instead rely on careful planning and design.

// Brooks's advice has not stood up well. It might have been state-of-the-art in 1975, but just a decade or two later major software systems cost as much as some downtown office buildings. We have not treated program code like _drafts_ of text for many, many years.

// The focus instead has been on reusing as much existing code as possible, we we have less code to write for each new program.

// Today, I think everyone in the industry agrees that it is better to plan to build a system incrementally, and to keep the system as you build it. This is the essence of iterative and incremental development, which is the basis for agile ways of working.

// Indeed, in 1987, Fred Brooks admitted that incremental development had emerged as a far better approach than trial and error, and that incremental development had changed his own approach to software development.

// I think today everyone agrees that, for the vast majority of software projects, the principle of "fail fast" is a bad one.

// We SHOULD avoid trial and error in software development. Don't just start coding without having a plan. Make sure you have all the prerequisites (eg. the definition of ready) in place – which may include designs – before construction begins.

// Code is expensive. It only take experience working on a few large programs to learn that you can
// void a lot of stress by planning ahead. Seasoned devs understand this – that our task is to do as little coding as possible!

// Preparation lays the groundwork for success or failure. If you start coding and you realize preparation has not been adequate – eg. you spot gaps in requirements – back up and pause progress until you have more info.

// === Organizational change

// Planning for software change is one thing. Planning for organizational change is another.

// Structuring an organization for change is much harder than designing a system for change.

// The project boss must work at keeping the managers and the technical people as interchangeable as their talents allow; in particular, one wants to be able to move people easily between technical and managerial roles.

// Organizing as a surgical team... is the long-run answer to the problem of flexible organization.

// === Program maintenance

// Program maintenance consists chiefly of changes that repair design defects, add incremental function, or adapt to changes in the use environment or configuration.

// The total lifetime cost of maintaining a widely-used program is typically 40% or more of the cost of developing it.

// Maintenance cost is strongly related to the number of users, because the more users there are, the more bugs will be found.

// There's a drop-and-climb curve in bugs discovered per month over a product's life.

// Fixing a defect has a substantial (20% - 50%) chance of introducing another. After each fix, one must run the entire bank of test cases previously run against a system to ensure that it has not been damaged in some obscure way (what we now call _regression_).

// Methods of designing programs so as to eliminate, or at least illuminate, side effects can have an immense payoff in maintenance costs. So can methods of implementing designs with fewer people, fewer interfaces, and fewer bugs.

// === System entropy rises over lifetime

// Brooks quotes research by Lehman and Belady in which they find that the total number of modules increases linearly with the release number of a large operating system, but that the number of modules affected increases exponentially with the release number.

// All repairs tend to destroy structure, to increase the entropy and disorder of a system. Even the most skillful program maintenance only delays the program's subsidence into unfixable chaos, from which there has to be a ground-up redesign.

////

"Project after project designs a set of algorithms and then plunges into construction of customer-deliverable software on a schedule that demands delivery of the first thing built."

The first version of a large-scale software system may be too slow, too big, difficult to use, etc. You then have to solve these problems – hopefully yuu can do this piece-by-piece, but the worst case scenario is you will have to start over if the design proves to be fundamentally flawed... "for even the best planning is not so omniscient as to get it right the first time."

Hence: "plann to throw one away; you will, anyhow".

''''

"The only constant is change itself."

"The first step is to accept the fact of change as a way of life, rather than an untoward and annoying exception. Cosgrave [TODO: add reference] has perceptively pointed out that the programmer delivers satisfaction of a user need rather than any tangible product. And both the actual need and the user's perception of that need will change as programs are built, tested, and used."

Brooks writes that, for hardware products like cars and computers, the existence of a tangible object "serves to contain and quantize user demand for changes". But "both the tractability and the invisibility of the software product expose its builders to perceptual changes in requirements."

Brooks is advocating the agile principle of *embracing change*, 25+ years before the manifesto for agile software development is written. It is inevitable, he writes, that objectives and requirements will change, and changes in development strategies and techniques are also inevitable.

"The throw-one-away concept is itself just an acceptance of the fact that as one learns, he changes the design."

*Plan the system for change*

This is done through modularization, extreme subroutining (which today we would call abstraction), careful definition of module interfaces – and complete documentation of these.

"Most important is the use of a high-level language and self-documenting techniques so as to reduce errors induced by changes."

"Quantizaion of change is an essential technique. Every product should have numbered versions, and each version must have its own schedule and a freeze date, after which changes go into the next version."

*Plan the organization for change*


"Structuring an organization for change is much harder than designing a system for change."

Plans, milestones, and schedules need to be treated as _tentative_, to facilitate change. But this is anathema to many organizations - where slippage of delivery plans is treated as a "failure of project management".

Agile - this is perhaps what we've got wrong. We have not explained _how_ organizations should implement the cultural change needed.

"Management structures also need to change as the system changes."

"This means... [keeping] managers and technical people as interchangeable as their talents allow."

Brooks writes about how flat organizational structures can really help facilitate this. He gives the example of Bells Labs that abolished job titles and hierarchies to everyone was an equal "member of the technical staff".

Brooks says this fits well with his model of *surgical teams* as "it has the effect of making a senior man feel that he does not demean himself when he builds programs, and [it] removes the social obstacles that deprive him of that creative joy."

Brooks says that tthe surgical team is "the long-run answer to the problem of the flexible organization." He explains: "it becomes relatively easy to reassign a whole surgical team to a different programming task when the organizational changes are necessary."

*Two steps forward and one step back*

Once a program is shipped to customers, afterward further delivery is called *maintenance* rather than *development* – the work now consists chiefly of repairing design defects. This may include adding features that are visible to the user.

Maintenance can cost 40% of the total cost of developing a software product. We tend to think of software development not as projects but as long-lived programs (products).

More users = more bugs found = more maintenance

image::./_/media/diagrams/bug-discovery-over-time.drawio.png[]

The bug rate drops off after the initial release, but then starts to gradually climb again -- this may be due to users fully exercising the new capabilities of the software, ie. they start to become really familiar with it, and so edge case bugs start to get shaken out.

Brooks discusses the far-reaching, often overlooked, impacts of doing lots of piecemeal repairs on a system. He sites studies by Lehman and Belady that "all repairs tend to destroy structure to increase the entropy and disorder of the system. ... As time passes, the system becomes less and less well-ordered. Sooner or later, the fixing ceases to gain any ground. Each forward step is matched by a backward one. Although in principle usable forever, the system has worn out as a base for progress."

Eventually, a "brand-new, from-the-ground-up redesign is necessary."

Brooks quotes CS Lewis: "Terrific energy is expanded – civilizations are built up – excellent institutions devised; but each time something goes wrong. Some fatal flaw always brings the selfish and cruel people to the top, and then it all slides back into misery and ruin."

Brooks concludes: "Systems program building is an entropy-decreasing process, hence inherently metastable. Program maintenance is an entropy-increasing process, and even ifs most skillful execution only delays the subsidence of the system into unfixable obsolescence."

Intriguingly, Brookes writes that "methods of designing programs so as to eliminate or at least illuminate side effects can have an immense payoff in maintenance costs." He suggests that having fewer people do the design and build, and having fewer interfaces, produces systems with fewer bugs – and such systems suffer less from entropy and therefore have longer useful lives.

////

== Chapter 12. Sharp tools

// The manager of a project needs to establish a philosophy and set aside resources for the building of common tools, and at the same time recognize the need for personalized tools.

// The debugging machine, or its software, also needs to be instrumented, so that counts and measurements of all kinds of program parameters can be automatically made.

// The requirement for target machine use has a peculiar growth curve: low activity followed by explosive growth, then a levelling off.

// Brooks writes about methods for scheduling teams' access to limited testing machines… this is not relevant any more.

// System debugging, like astronomy, has always been done chiefly at night.

// The tool that saves the most labor in a programming project is probably a text-editing system.

// Voluminosity in system documentation introduces a new kind of incomprehensibility, but is preferable to severe under-documentation – which, in my experience, still exists. Rather, documentation tends to be chaotic – think unstructured, poorly maintained Confluence spaces, for example.

// Brooks encourages the adoption of high-level programming languages, which are now ubiquitous. They improve productivity, introduce fewer bugs, and make debugging easier.

// Brooks notes, as early as 1975, that the classical objections of function, object-code space, and object-code speed have been made obsolete by the advance of language and compiler technology.

// Interactive systems will never displace batch systems for some applications. This is still true in 2025, and it probably always will be. Interactive programs and batch processes are two entirely different use cases.

////

"A good workman is known by his tools."

"Each master mechanic has his own personal set [of tools], collected over a lifetime adn carefully locked and guarded – the visible evidence of personal skills."

"the programmer keeps little editors, sorts, binary dumps, disk space utilities, etc., stashed away in his file."

Brooks says that is undesirable for programming projects where "the essential problem is communication, and individualized tools hamper rather than aid communication."

"it is obviously much more efficient to have common development and maintenance of general-purpose programming tools."

Brooks says that you need a mix of specialized and personalized tools.

He advocates "one toolmaker per team... [who] masters all the common tools and is able to instruct... in their use. He also builds the specialized tools his boss needs."

"What are the tools about which the manager must philosophize, plan, and organize? First, a _computer facility_. This requires machines, and a scheduling philosophy must be adopted. It requires an _operating system_, and service philosophies must be established. It requires _language_, and a language policy must be laid down. Then there are _utilities_, _debugging aids_, _test-case generators_, and a _text processing system_ to handle documentation."

The rest of the chapter looks at each of these in turn. Today, we need not spend nearly so much time and effort thinking about our tooling. And we don't care so much about our systems being idle for long periods of time.

The chapter provides an interesting step back in time to when every aspect of software delivery had to be carefully considered – so much is now just readily available, often free or as a low-cost subscription.

"The most important tools for system programming today are two that were not used in OS/360 development almost a decade ago. They are still not widely used [in 1975], but all evidence points to their power and applicability. They are (1) high-level language and (2) interactive programming. I am convinced that only inertia and sloth prevent the universal adoption of these tools; the technical difficulties are no longer valid excuses."

Brooks explains why the adoption of high-level languages (by which we mean higher than assembly) were still subject to push-back in 1975.

high-level + interactive => "a pair of sharp tools indeed"

I like the idea of _precision_ in tooling, especially in debugging.

////

== Chapter 13. The whole and the parts

// Detailed architectural effort (discussed in earlier chapters) not only improves the *ease of use* of a software product, but also makes it easier to build, and reduces the number of defects.

// Many defects concern aspects that were never quite fully specified.

// Brooks suggests that, before any code itself is written, the specification should be handed to an outside testing group to be scrutinized for completeness and clarity. The developers themselves cannot do this.

// "Wirth's top-down design [by stepwise refinement] is the most important new programming formalization of the [1965-1975] decade." Wirth advocates using as high-level a notation as possible on each step.

// A good top-down design avoids bugs in four ways:

// 1. xxx
// 2. xxx
// 3. xxx
// 4. xxx

// Sometimes one has to go back, scrap a high level, and start over.

// *Structured programming* (designing programs whose control structures consist only of a specified set that govern blocks of code, versus miscellaneous branching) is a sound way to avoid bugs and is the right way to think.

// System debugging is far harder than component debugging. It helps to plan system debugging sessions before starting – ie. have a strategy, a systematic and planned approach.

// System debugging should begin only after all the components are proven to work. Do not use system testing to try to smoke out interface bugs.

// Add one component at a time during system debugging.

// It is worthwhile to build lots of debugging scaffolding and test code – this might account for as much as 50% as much of the product being debugged.

// One must control and document changes and versions, with team members working on *playpen* copied.

////

This chapter is about "how does one integrate a tested set of component programs into a tested and dependable system?"

It's about that last step of integrating and testing a complete, whole system from its pre-fabricated, pre-tested component parts. Of course today we do this incrementally – it's not all done in one step at the end.

This process is really about "designing the bugs out". Techniques that help include:

* *Conceptual integrity* makes a program easier to build, easier to use, and less subject to bugs.

* Painstaking architectural effort: "The crucial task is to get the product defined. Many, many failures concern exactly those aspects that were never quite specified." ... "careful function definition, careful specification, and the disciplined exercise of frills of function, and flights of technique all reduce the number of system bugs that have to be found."

"Long before the code exists, the specification must be handed to an outside testing group to be scrutinized for completeness and clarity."

This is not something we to today – it was perhaps only necessary in the very early days of development when it was costly to _change_ code. But it remains necessary if you want fixed budgets for delivery.

"[Developers] will happily invent their way through the gaps and obscurities."

The following ideas were relatively embryonic at the time, but Brooks clearly saw that these had potential:

*Top-down-design*

"I am persuaded that top-down design is the most important new programming formulation of the decade."

Brooks reviews a 1971 paper by Niklaus Wirth, title _Program Development by Stepwise Refinement", which formalized a design process that divided a system build into:

- Architecture
- Implementation
- Realization

The three are a series of _refinement steps_.

"One sketches a rough task definition and a rough solution method that achieves the principal result. Then one examines the definition more closely... and one takes the large steps of the solution and breaks them down into smaller steps."

"From this process one identifies _modules_ of solution or of data whose further refinement can proceed independently of other work."

You use a high-level notation for each step, exposing the concepts and concealing the details... until further refinement becomes necessary.

Top-down benefits:

* Clarity in the structure and representation
* Makes it easier to define requirements and functions
* Partitioning and independence of modules, reduces system bugs
* The suppression of details makes flaws in the design more apparent

You may still have to start over with a fresh high-level design, but this approach reduces the temptation to do the opposite: trying to salvage a bad design with lots of patches and "all kinds of cosmetic relief".

*Structured programming*

Structured programming is a programming paradigm characterized by source code that uses block-based source code structure to encode control flow such as sequence, selection (i.e. if-then-else and switch) and iteration (i.e. for and while).

Originally, the central goal of the structured programming movement was to eliminate the need for and use of the goto statement. As goto provides powerful and flexible flow control, it can be used to write any arbitrarily complex algorithm, but the resulting code often has significant quality issues, commonly described as spaghetti code. Structured programming replaces goto with constructs that tend to result in better code. The paradigm became popular and for the most part achieved the goal of supplanting goto. In fact, its ubiquity is so thorough that for much of software development, it is simply the way code is written, no longer a topic of discussion as it once was.

Structured programming was a new idea at the time. Brooks writes there is merit in the idea!

*Component debugging*

Prior 20 years saw great leaps forward in approached to debugging programs, from "on-machine debugging" to "interactive debugging" (ie. step-throughs and breakpoints).

These tools have changed more substantially still in the last 50 years. But the fundamentals were already formed in the 1970s.

Brooks identified *system debugging* as one of the hardest things to do in 1975. He says you should expect it to take longer than you think it will.

He says system debugging must be done "debugged components" – what we would now call unit tests (then: component tests).

There is a nod toward integration testing – "using the pieces to test each other". The case for going straight to system testing is the reduced effort of needing to do lots of test scaffolding.

Scaffolding = all programs and data built for debugging and testing purposes, but not intended to be included in the final product.

"It is not unreasonable for there to be half as much code in scaffolding as there is in product."

Forms of scaffolding:

* Dummy components: interfaces and faked data.
* Miniature file
* Auxiliary programs: generators for test data, etc.

////

== Chapter 14. Hatching a catastrophe

// // In chapter 14, Brooks suggests the use of [PERT charts] to keep track of critical tasks in a project.

// "How does a project get to be a year late?… One day at a time."

// Day-by-day schedule slippage is harder to recognize, harder to prevent, and harder to make up, than calamities.

// The first step in controlling a big project on a tight schedule is to _have_ a schedule – made up of milestones and dates for them. Milestones must be concrete, specific, measurable events defined with knife-edge sharpness.

// Chronic schedule slippage is a morale-killer.

// _Hustle_ is essential for great programming teams, just as for great baseball teams.

// There is no substitute for a critical-path schedule. The preparation of the critical-path schedule is the most valuable part of its use; this process identifies the dependencies, and estimating the components forces a great deal of very specific planning very early in a project.

// Delivery managers need accurate status reports. Accepting status reports without panic or preemption will encourage honest reporting. Status reviews must be shared.

////

"How does a project get to be a year late? ... One day at a time." – Sophacles

Why are projects late?

Many disasters are caused by termites, not tornadoes!

Major incidents are actually easier to handle – the whole team rises to the occasion.

The problem is when the schedule slips imperceptibly. "Day-to-day slippage is harder to reorganize, harder to prevent, harder to make-up."

''''

How does one control a big project on a tight schedule?

First: have a schedule! This means having clearly-defined events, called *milestones*, that have a date. The milestones must be concrete, eg. "debugging version passed 100% of test cases". Milestones must be "shard edged and unambiguous" – then you can't lie that you'vce delivered what you said you would, because it's verifiable.

"The fuzzy milestone is the harder burden to live with."

Brooks suggests the use of PERT charts. "The preparation of a PERT chart is the most valuable part of its use. Laying out the network, identifying the dependencies... force a great deal of very specific planning very early in a project."

Brooks suggests a dedicated sub-team, calls the Plans and Controls team. He says this is "invaluable for a large project". It works better when these people are not directly involved in the building, but are regularly reviewing its progress.

"The Plans and Controls group is the watchdog who renders imperceptible delays visible andd who points up the critical elements. It is the early warning system against losing a year, one day at a time."

////

== Chapter 15. The other face

// // Chapter 15 provides guidance on documenting large programs. The book also summarizes modeling notations that were popular at the time, and he draws comparisons between [top-down] and [bottom-up] approaches to system design.

// This is all about *user documentation* (as opposed to developer documentation).

// The documentation is "the other face" of the product to the user. This is just as important as the product itself.

// Even for the most private of programs, prose documentation is necessary, for memory will fail the user-author.

// But user documentation is rarely done very well. There are many reasons for this, including schedule pressure, but Brooks identifies knowledge of _how_ to document effectively as being a key reason. Technical writing, still in 2025, is a neglected art, and rarely appears listed in job requirements.

// Most documentation fails in giving too little _overview_. Good documentation will stand way back, then zoom in slowly.

// Critical user documentation should be drafted before the program is built, for it embodies basic planning decisions. It should describe nine things:

// 1. xxxx
// 2. xxxx
// 3. xxxx
// 4. xxxx
// 5. xxxx
// 6. xxxx
// 7. xxxx
// 8. xxxx
// 9. xxxx

// A program should be shipped with a few test cases, some for valid input data, some for borderline input data, and some for clearly invalid input data – this is for the benefit of end users.

// Developer documentation – documentation for program internals, for the people who must modify the program – should contain five kinds of things:

// 1. xxxx
// 2. xxxx
// 3. xxxx
// 4. xxxx
// 5. xxxx

// The flow chart is the most oversold piece of program documentation. Logic diagrams have been made obsolete by high-level programming language. A flow chart is just a _diagrammed high-level language – so it's redundant.

// To keep documentation maintained, is is crucial that is be incorporated into the source program, rather than be kept as a separate document.

// Three notions are key to minimizing the volume of documentation:

// * Use parts of the program that have to be there anyway, such as names and declarations, to carry as much of the documentation as possible.

// * Use space and format to show subordination and nesting to improve readability.

// * Insert the necessary prose documentation into the program as paragraphs of comments, especially in module headers.

// In documentation for use by program modifiers, tell _why_ things are like they are, rather than merely _how_ they are. _Purpose_ is the key to understanding; even high-level language syntax does not at all convey purpose.

// Self-documenting programming techniques find their greatest use and power in high-level languages used with on-line systems, which are the tools one _should_ be using.

////

This chapter is essentially about user-facing documentation, or more generally user-interfaces – it's what tels users how to use a program.

The problem is that the user is remote from the developers in both time and space.

"For the program product, the other face to the user is fully as important as the face to the machine."

In the 1960s/1970s, the effort was getting complex programs to work! "A computer program is a message from a man to the machine."

Today, we often start the other way around – at the UI.

Brooks writes that lots of levels of documentation are required:

* Purpose
* Environment
* Domain and range of output
* Functions realized
* Algorithms used
* I/O formats
* Operating instructions
* Options
* Running time
* Accuracy and checking

Brooks advocates that development and maintenance of UI documentation be done in conjunction with changes to the program itself.

(Most of this chapter is not relevant any more – users don't require such low-level documentation.)

*Self-documenting programs* - this idea is closer to how we think about UXD today.

"We typically attempt to maintain a machine-readable form of a program and an independent set of human readable documentation."

Better for these to coexist side-by-side. They change together, and therefore remain in sync.

"The solution, I think, is to merge the files, to incorporate the documentation in the source program."

Enforces proper maintenance of user documentation - as part of the UI.

Such programs are called *self-documenting*.

He then goes on to explain how this might be achieved in the programs of the 1960s and 1970s. It was hard! But, Brooks writes, it is becoming easier in high-level languages.

////

== Chapter 16. No silver bullet

// Title: "No silver bullet - essence and accident"

== Chapter 17. "No silver bullet" revisited

(Supplementary chapter in the 20th anniversary edition)

== Chapter 18. Propositions of The Mythical Man-Month: true or false?

(Supplementary chapter in the 20th anniversary edition)

== Concluding thoughts

Throughout the history of computing, advances in technology have created opportunities for ever more ambitious software. The resources and tools at our disposal are as powerful as they have ever been – think cloud computing, virtualization and containerization, continuous integration and automated deployment pipelines, and AI-assisted coding environments. But the productivity gains afforded by these tools are offset by the increases in complexity of the software that exists in the world today.

Of course, some of the challenges today are different from what they were in the time of OS/360. We are no longer physically constrained by computing resources – these are abundant, easily sourced, and cheap. Yet physical constraints remain for many categories of software – for example, real-time systems, embedded systems, and systems with strict performance requirements.

The book closes with this epilogue:

[quote, Fred Brooks]
____
The tar pit of software engineering will continue to be sticky for a long time to come. One can expect the human race to continue attempting systems just within or just beyond our reach; and software system's are perhaps the most intricate and complex of man's handiworks. The management of this complex craft will demand our best use of new languages and systems, our best adaptation of proven engineering management methods, liberal doses of common sense, and a God-given humility to recognize our fallibility and limitations.
____

Amen.

''''

== Related reading

* https://curtclifton.net/papers/MoseleyMarks06a.pdf[Out of the Tar Pit] — 2006 paper by Ben Moseley and Peter Marks.
