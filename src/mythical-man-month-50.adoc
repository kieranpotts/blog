= The Mythical Man-Month at 50
Kieran Potts, 19 December 2025
:description: Fred Brooks's classic book The Mythical Man-Month was published 50 years ago. It was hugely influential on the then-nascent discipline of software development. How does it stand up today?
:docinfo: shared
:nofooter:

Fred Brooks's classic book _The Mythical Man-Month_ was published 50 years ago. It was hugely influential on the then-nascent discipline of software development. How does it stand up today?

https://en.wikipedia.org/wiki/Fred_Brooks[Frederick P Brooks Jr's] classic book _The Mythical Man-Month: Essays on Software Engineering_ was published in 1975 – 50 years ago. The book was one of the first published analyses of the challenges of large-scale software development. It introduced many ideas and principles that were hugely influential on early practitioners of our craft. But which ideas have withstood half a century of technological change, and which have not?

I got myself a copy of the original 1975 edition and the extended 20th anniversary (1995) edition, which added four new chapters. Here are my thoughts, organized by the main themes of the book and roughly aligning with the order of the chapters.

== The tar pit

_The Mythical Man-Month_ is more of an anthology of standalone essays rather than a cohesive thesis. Nevertheless, there are some key themes that run throughout. The most prominent theme is the one introduced in the opening chapter: that the core challenge of software development is the management of complexity.

Brooks draws the colorful analogy that large-scale software development is like "`the mortal struggles of great beasts in the tar pits`". This is represented by the book's cover image, a sketch of Charles Knight's 1925 painting that depicts the great mammoths of the Pleistocene struggling to free themselves from the tar pits of Southern California.

image::./_/media/images/the-mythical-man-month.jpg[]

"`Large and small, massive and wiry, team after team has become entangled in the tar,`" Brooks writes. His thesis is that it is never one problem, but rather a combination of intractable problems, some unexpected, that make it difficult to move complex projects forward. "`No one thing seems to cause the difficulty – any particular paw can be pulled away. But the accumulation of simultaneous and interacting factors brings slower and slower motion.`"

Despite the immense technological advances of the last half-century – in computer hardware, in programming languages and runtime environments, and in tools and automation that support every aspect of software delivery – the core challenge of software development remains the management of complexity.

Throughout the book, Brooks draws on his own experiences, notably as the manager who oversaw the initial design of IBM's OS/360 operating system. At the time, OS/360 was one of the biggest, most ambitious, most complex software projects ever attempted. At the peak of the project, more than 1,000 people worked on it.

But, Brooks acknowledges, the project was not "`wholly successful`". The initial release of OS/360, in 1966, was delivered "`late, it [used] more memory than planned, the costs were several times the estimate, and [the first version] did not perform very well`".

The opening chapters serve as Brooks's post-mortem of the OS/360 project. He concludes that the fundamental reason for the project's difficulties was that the overall costs of delivering such a large-scale software system had been massively underestimated at the start. This happened because the estimates were based solely on the construction of the individual parts of the system. What they had not accounted for was: (a) the integration costs of all those components; and (b) the "`productization`" of the whole solution.

Brooks estimates that the work of designing the interfaces between all the components of a system, coordinating their integration, and incrementally extending integration tests, has the potential to triple the initial cost of coding all the components in isolation. Costs may triple again for all the work that goes into preparing a large-scale software system for distribution as shrink-wrapped software for general use by the public. For the OS/360 project, they had not fully accounted for how much extra rework and testing would be needed to make the system run reliably in "`many operating environments, for many sets of data`", and for time spent preparing user-facing documentation and other packaging.

Brooks estimates that, in total, building large, general-purpose, shrink-wrapped software products can cost up to nine times (3x3) more than writing all the code as separate, non-integrated, private libraries.

In other words, programming effort is a small proportion of the overall cost of a large-scale software project. This analysis stands up well today. It is widely understood in academic circles that the production of computer program code and configuration is a small proportion of the overall cost of building large-scale commercial software systems.

Brooks suggests that the costs of a large-scale software project typically break down into approximately 1/3 for design, 1/6 for coding, 1/4 for component testing (ie. unit and integration testing), and 1/4 for system (end-to-end) testing. In a later chapter, Brooks says that, unfortunately, you cannot estimate the cost of a software project simply by working at the coding effort and then multiplying for other cost factors. "`The coding is only one-sixth or so of the problem, and errors in its estimate or in the ratios could lead to ridiculous results.`"

In my experience, we still have a tendency to estimate development costs based primarily on the coding of individual modules, rather than considering the integration of those modules into a cohesive system, and the subsequent productization of that system for distribution to end users.

// Programming effort increases as a power of program size. Brooks says that some published studies from the time show the exponent to be about 1.5. For example, one study showed that effort to code a program half the size of another took only one-fourth of the effort to code the other program. Studies also show that productivity varies significantly by category of software, eg. between operating systems and compilers.

// Programming productivity can be increased by as much as five time when a suitable high-level programming language is used – something that was not available at the time of the OS/360 project.

== The mythical man-month

The eponymous second chapter deals with the perennial issue of software projects being notorious for going over budget, being delivered later than estimated, and failing to meet expectations in functionality and performance.

Besides the cost overruns associated with integration and productization experienced on the OS/360 project, explored in the previous chapter, Brooks considers numerous other reasons why estimating and scheduling of software projects is so error-prone.

=== Optimism

The first explanation the author gives for poor project estimation is a bias toward optimism.

Brooks writes that "`all programmers are optimists`". He hypothesizes that, because the age distribution of programmers in 1975 was skewed toward younger age groups, and because younger people tend to be more optimistic than the population at large, then software project estimates are particularly prone to being wildly optimistic.

I'm not wholly convinced by this argument. Sure, younger developers lack the necessary experience to do accurate estimates. But I've found senior developers to be just as guilty of optimism bias. Contingency planning and risk management are still poorly practiced in many software projects today – regardless of who's drawing up the project plans.

Brooks adds that the very notion that the development of complex software systems can be accurately estimated is flawed. He writes that "`the programmer builds from pure thought-stuff`" and that "`for the human makers of things, the incompleteness and inconsistencies of our ideas become clear only during implementation. Thus it is that writing, experimentation, 'working out' are essential disciplines for the theoretician.`"

Brooks reflects that large-scale software development, like OS/360, is inherently hard. The reality of developing commercial software for a living, Brooks writes, is that there are many "`dreary hours of tedious, painstaking labor`", often involving analyzing code written by other people who are no longer involved in the project.

This I find to be a more convincing argument. Software development is an inherently complex and unpredictable activity. In every software project, even those with stable and known requirements, there will always be some requirements that are emergent. Some requirements may emerge only at the time of construction, or even later, when working software is finally put into the hands of real users. This is the nature of software development, which is more of a design problem than a construction task.

I have long held the view that the very notion that the development of software can be perfectly planned and accurately estimated is deeply flawed. Yet in 2025, as in 1975, the belief that the delivery of complex software can be planned in meticulous detail, and costs controlled accordingly, is still widely held throughout our industry.

=== Progress is not always correlated with effort

The second explanation that Brooks provides for poor estimation is the assumption that delivery schedules can be shortened by adding more programmers. Famously, Brooks writes that "`adding manpower to a late software project makes it later.`" – a quote that will forever be known as Brooks's Law.

Brooks's central argument for this is that adding people to a late project increases total effort. There's extra effort involved in reorganizing the project delivery plan and managing the larger team. Meanwhile, in-flight work streams are disrupted by the "`repartitioning`" of work. There follows a permanent increase in intercommunication, required to coordinate the development of dependencies and interfaces, and to coordinate integration testing. There's also more time spent training and onboarding new people.

And some programming tasks just cannot be parallelized. Some tasks can only be done sequentially, and so cannot be shared between more programmers. If programmers are already optimally allocated to these tasks, adding more programmers will not speed up their completion. To illustrate this point, Brooks offers the suitably colorful analogy of child bearing:

[quote, Fred Brooks]
____
The bearing of a child takes nine months, no matter how many women are assigned.
____

Brooks coins the term "`man-month`" to represent one unit of additional manpower (one person working for one month). Because adding resources to a project in the form of extra man-months increases overall effort, it does not necessarily correspond to an increase in the speed of progress. And yet, 50 years ago, Brooks says this was a widely held belief and a common practice – hence the "`mythical`" nature of extra man-month resources!

[quote, Fred Brooks]
____
Men and months are interchangeable commodities only when a task can be partitioned among many workers _with no communication among them_. This is true of reaping wheat or picking cotton; it is not even approximately true of systems programming.
____

Thus, once a schedule is proven to be unrealistic, there may not be anything that can be done to put the project back on track. Adding more people to a project _will_ decrease the productivity of individual team members, and there comes a tipping point where this decrease in productivity more than offsets the overall addition of resources – so delivery speed _slows_ despite the extra manpower.

.Correlation between time and the number of workers
image::./_/media/diagrams/men-versus-months.drawio.png["",468]

This graph shows that software projects have an optimal division of labour – where delivery is maximized by efficient allocation of resources – and delivery cannot be further optimized beyond this point. Brooks observes that the more complex the interrelationships between the component parts of the system under construction, the greater this effect. Hence the management of complexity is identified as the core challenge of software development. The simpler the design, the more opportunities you will have to build out the solution faster.

Even today, managers routinely believe that adding more people to a late project can solve schedule slippage. I've seen this myself. It's especially commonplace in consultancies and outsourcing firms, where the software house bills its customers in man-hours and therefore has a commercial incentive to add as many people as possible to their projects. But I've seen it in software houses, too. They ought to know better.

=== Regenerative schedule disaster

The third explanation that Brooks provides for poor estimation is what he terms "`regressive schedule disaster`".

Brooks writes that project progress tends to be poorly monitored, so when it becomes apparent that schedules have slipped, it's usually already too late to do anything about it. If it's too late to implement effective strategies, like decreasing scope or simplifying the design, the only thing left to try is to throw more people at the problem – which makes matters worse.

In this situation, Brooks says the only recourse is to reschedule the work with the original team members, "`un-augmented`" by new recruits. This has the effect of delaying completion of the project, but at least overall costs do not needlessly increase through spend on additional staff who will ultimately be under-utilized.

Better to increase the number of months than the number of men.

=== System testing must be done last

The fourth explanation that Brooks gives for poor estimation is that system testing and debugging must be done last, due to the sequential nature of the work. Consequently, testing "`is usually the most mis-scheduled part of programming`" and multiple rounds of testing and debugging can end up accounting for as much as half of the overall development schedule.

In the intervening years, our industry has universally adopted iterative and incremental development practices, in which small chunks of work are delivered at regular intervals with testing and debugging done in parallel to the design and construction. Thus, rather than testing being left until the system is complete, instead the correctness of the evolving system is continuously evaluated throughout its development life cycle.

Through continuous integration and testing, we've solved the problem of defects in the design and construction being discovered late. At least this is rarely a cause for project overruns anymore.

=== Gutless estimating

The fifth and final explanation that Brooks gives for poor estimation of software projects is the tendency we have to work to schedules dictated by our customers. WHat we ought to do, Brooks writes, is be brave and attempt to make a reasonable guess about the real effort required to deliver a satisfactory product.

Brooks uses the analogy of cooking an omelette. It typically takes a couple of minutes to cook an omelette. But if, after two minutes, the omelette is not set, the customer has two choices: wait, or eat the omelette raw. The chef has a third choice: turn up the heat. But the effect would be to serve a poor quality product – burnt on the outside, and perhaps still raw in the centre.

[quote, From a menu of a New Orleans restaurant]
____
Good cooking takes time. If you are made to wait, it is to serve you better, and to please you.
____

In the delivery of commercial software, we have a tendency to take the third option: to turn up the heat and try to deliver products within the schedules desired by our customers. "`False scheduling to match the patron's desired date is much more common in our discipline than elsewhere in engineering,`" Brooks observes.

Brooks contends we should instead have the "`courteous stubbornness`" of a chef who refuses to serve a dish until it is ready. Construction of good software, like cooking, takes time. Some tasks just cannot be hurried without spoiling the result.

Brooks suggests that the underlying reason for such widespread "`gutless estimating`" in our industry is that we do not have mature models for estimating software work. "`It is very difficult,`" he writes, "`to make a vigorous, plausible, and job-risking defense of an estimate that is derived by no quantitative method, supported by little data, and certified chiefly by the hunches of the managers.`"

50 years later, there remains a lack of maturity in the methods and tools we use for estimation. Overuse of proxy measures, such as T-shirt sizes and story points, which do not directly correspond to real-world effort, rather than more quantitative data-driven estimation techniques, is commonplace today.

// Estimations tend to be done very early in the development lifecycle, too. We tend to make estimates base on high-level requirements – even vague and incomplete ones – rather than based on comprehensive, high-fidelity solution designs. If you want good estimates, you need the solution to be sufficiently flesh-out with enough detail to reveal the true scope and complexity of the problem. Good estimations are done bottom-up from low-level technical designs, rather than top-down from high-level business requirements. This is true of every engineering discipline.

== The surgical team

In the third chapter, Brooks pitches his solution to the problems of large-scale software development: the surgical team.

The roots of this idea lie in the observation that having a small number of very skilled programmers on a team often proves to be more effective than having a large number of average ones.

Brooks quotes a now-infamous https://dl.acm.org/doi/10.1145/362851.362858[1968 paper] by Sackman _et al_ that postulated that very good programmers can be up to ten times as productive as poor ones.

[quote, Sackman et al, Communications of the ACM January 1968]
____
These studies revealed large individual differences between high and low performers, often by an order of magnitude. It is apparent from the spread of data that very substantial savings can be effected by successfully detecting low performers.
____

This is the origin of the idea of the 10x programmer. However, the findings of the Sackman paper were debunked by subsequent research. The 1968 study tested programmers on tasks that did not represent real-world programming problems. Neither did it account for the impact of collaboration, which we now know to be more important than individual capability. But at the time, the qualitative analysis provided by this paper reinforced qualitative observations made by Brooks and other project managers that small "`sharp`" teams are better than large blunt ones. Better for software development teams to be composed of a small number of "`first-class`" programmers rather than many mediocre ones.

It is why, Brooks concludes, there are many accounts of two programmers working in a garage to build "`an important program that surpasses the best efforts of large teams`". The cliché of the garage startup has deeper roots than I realized!

Brooks expands on his earlier point that throwing lots of man-months at a project can actually slow down delivery. He writes, "`the brute-force approach is costly, slow, inefficient, and produces systems that are not conceptually integrated.`"

But the problem with small teams is they are too small for really big problems. Brooks notes there were over 1,000 people working on OS/360 at the peak of that project, and a smaller 200-man team would have taken 25 years to deliver the same product. For large-scale software projects, the delivery timescales achievable by small teams are just not commercially viable.

If we want to prioritize development efficiency and the quality of the final product, we should have small teams of highly skilled, experienced practitioners doing the design and construction. But to deliver large systems in a timely manner, we need very large teams. How can we reconcile these two constraints?

Brooks draws on a solution first proposed by Harlan Mills in a 1971 IBM paper.

[quote]
____
Mills proposes that each segment of a large job be tackled by a team, but that the team be organized like a surgical team rather than a hog-butchering team. That is, instead of each member cutting away on the problem, one does the cutting and the others give him every support that will enhance his effectiveness and productivity.
____

The idea is there would be, not one giant team, but multiple smaller and independent teams. The overall solution is designed as a series of small subsystems, with each subsystem designed and built by one of the teams.

Each team operates similarly to a surgical team in a hospital. Each team has a chief programmer, the surgeon, who is in charge of the whole thing. The rest of the team members try to help him complete the project (the surgery).

The chief programmer is responsible for defining and maintaining the conceptual integrity of his team's part of the overall solution. "`He personally defines the functional and performance specifications, designs the program, codes it, tests it, and writes its documentation`". The chief programmer is supported by a copilot who researches design options for the chief programmer to consider, drawing upon the experience and expertise of the rest of the team. The idea is that "`few minds are involved in design and construction, yet many hands are brought to bear`".

The chief programmers across all the teams collaborate with each other to coordinate the integrations between the subsystems for which they are each responsible. By structuring an organization as a hierarchy of delivery teams like this, overall communication overhead is minimized. You need only to coordinate the work of the chief programmers, who represent a small portion of the overall number of technicians. Large-scale projects are thus more efficient and more scalable.

Mills named this team structure the https://wiki.c2.com/?ChiefProgrammerTeam[chief programmer team]. Brooks rechristened it the surgical team.

Although terms like "`surgical team`", "`chief programmer`", and "`copilot`" will be unfamiliar to most software developers today, the underlying principles are well understood. The responsibilities of the chief programmer are today split between roles like technical lead and solution architect. The concept of having a chief programmer supported by a copilot today manifests itself in the pair programming methodology (and, more recently, in AI-augmented programming). And surgical teams are conceptually similar to the process of mob programming.

Harlan Mills' work, later popularized by Brooks in _The Mythical Man-Month_, laid the groundwork for the software development best practices of 2025.

Of source, some of the details of the original surgical team design are no longer relevant. Besides the chief programmer and copilot, the original surgical teams also had an administrator to "`handle money, people, space, and machines`"; a technical editor responsible for maintaining documentation; a "`program clerk`" responsible for "`maintaining all the technical records of the team in a programming-product library`"; a "`toolsmith`" who implements any special tools needed by the team, such as for "`file-editing, text-editing, and interactive debugging`"; a "`language lawyer`", someone who is an expert in the programming language and operating system, and who provides consultancy to the team in how best to use them; and a tester, responsible for preparing suitable test cases from the functional specifications, and devising dummy data for day-to-day debugging. Oh, and the administrator and editor would each have their own personal secretaries. Different world!

Today, most roles of the surgical team have been automated away or absorbed into the broad responsibilities of programmers and testers. Every team member now works at the coalface, with no supporting roles. In the old surgical team model, only the chief programmer – or their deputy – actually wrote code, while two or three others handled support duties. But that setup wasn't about improving communication so much as about dealing with the practical constraints of the era, when costly storage and disk access couldn't be shared by everyone at once. Today there are no such constraints.

As for the myth of the 10x programmer, this remains a regrettable legacy of ideas that emerged in the 1960s and 1970s. Today, the software industry still has an unfortunate habit of glorifying "`rockstar`" developers and undervaluing teamwork and soft skills.

== Conceptual integrity

Brooks is perhaps most famous for his invention of the concept of conceptual integrity.

The dominant theme throughout _The Mythical Man-Month_ is the question of how best to manage complexity in large-scale software systems. Maintaining conceptual integrity, Brooks argues, is the best way of containing complexity as a codebase sprawls.

Conceptual integrity is a quality of a system that emerges from its high-level design. A system with high conceptual integrity is one where all its concepts, and their relationships with each other, are applied in a consistent way throughout. A consistent design philosophy flows through all subsystems. Anywhere you look in the codebase, it demonstrates the same balance of competing forces.

A conceptually integrated system tends to be faster to build and test, and easier to maintain. We can more confidently change parts of such systems, because we can draw upon our mental map of the architecture and understand intuitively the full repercussions of making our changes.

[quote, Fred Brooks]
____
I will contend that conceptual integrity is _the_ most important consideration in system design. It is better to have a system omit certain anomalous features and improvements, but to reflect one set of ideas, than to have one that contains many good but independent and uncoordinated ideas.
____

I think few modern architects would dispute Brooks's notion that conceptual integrity is one of the most important principles of software design, though today we are more likely to use terms like "`cohesion`" and "`consistency`" to refer to the same qualities of a system.

The difficult is in achieving it. For a system to have high conceptual integrity, Brooks says "`the entire system... requires a system architect to design it all, from the top down`". This is difficult to do in large-scale software projects because of the division of labour. In large-scale software projects, the implementation is necessarily broken up into lots of small pieces, each designed and constructed independently by different programmers, who each make different choices and trade-offs.

Brooks draws a parallel with European cathedrals, most of which "`show differences in plan or architectural style between parts built in different generations by different builders`". In software, Brooks notes, such conceptual disunity arises not from the passage of time – hundreds of years separating phases of functional extension – but from the decomposition of the design into "`many tasks done by many men`".

The solution offered by Brooks is to have one system architect who designs the whole system from top-to-bottom. Multiple surgical teams are overseen by a chief architect, so that the "`design ... proceed[s] from one mind, or from a very small number of agreeing resonated minds`", to maintain conceptual integrity.

In Brooks's development model, design and implementation are two distinct phases. First, a system architect defines the interface of the system, then the builders arrive and define the internal implementation. "`The separation of architectural effort from implementation is a very powerful way of getting conceptual integrity on very large projects. `"

Besides maintaining conceptual integrity, the horizontal division of labour between architecture and implementation also has the happy side-effect of simplifying communication flows within teams.

Today, we know this development model as top-down design. You start with a clear understanding of the user interface, the overall architectural style that you want to achieve, and the architectural patterns that you want to use. Within that overall design framework, the solution is broken down into a hierarchy of smaller, more manageable subsystems, modules, and components – each initially designed as a black box (only their interfaces are specified, not their internal workings). Each component is then refined in a stepwise fashion, with internal details described in greater detail. Additional levels of dependencies and interactions are added incrementally, until the complete system is fully specified.

Top-down design was promoted in the 1970s by IBM researchers Harlan Mills and Niklaus Wirth. Mills had implemented this method with success in a project for the New York Times, leading to the approach being adopted throughout IBM and then the wider IT industry. Wirth, the creator of the Pascal programming language, also advocated for top-down design in his work. He authored an https://dl.acm.org/doi/10.1145/362575.362577[influential paper] titled "`Program Development by Stepwise Refinement,`" published in 1971, which outlined the principles of top-down design.

Top-down design contrasts with bottom-up design, which emphasizes building a system from small, primitive components, gradually integrating lots of small parts to compose the complete solution. 

Top-down design methods were favored in software development until the late 1980s. Ever since, bottom-up design has been more highly regarded. Top-down design has come to be associated with big design up-front and waterfall methodologies, which are considered old-fashioned and inflexible, while bottom-up design is associated with lean and agile methodologies, which are considered more modern and flexible.

In practice, all software projects combine elements of both top-down and bottom-up design. Only the relative weighting of the two approaches varies from project to project. Mature software development practices do not view either approach as fundamentally superior but instead see them as mutually beneficial – good software design is about finding a reasonable balance of the two approaches.

In _The Mythical Man-Month_, Brooks draw parallels in the trade-offs between autocracy and democracy. He acknowledges that his proposed top-down approach to architecture means that the architects become something of an aristocracy within the technical domain, and that the demographic ideals that help to form cohesive, engaged teams are sacrificed. "`Are not the architects a new aristocracy, an intellectual elite, set up to tell the poor dumb implementers what to do?`" Brooks asks himself. "`Won't one get a better product by getting the good ideas from all the team, following a demographic philosophy…?`"

Brooks concludes that a reasonable balance must be found between demographic and autocratic approaches to solution design. Everyone should be able to contribute ideas, but ultimately there must be a single authority who makes the final decisions.

Both architects and implementers have important roles to play in system design, Brooks argues. Architects, which design the external specification (ie. the user interface), will have a disproportionate influence over the ease of use of the product. On the other hand, the compound effect of all the many low-level design choices made by the implementors will determine the eventual real-world performance of the product.

Brooks also makes the point that implementation – the raw coding – is also a form of creative work, just one that operates at a different level of abstraction to the architecture. "`The opportunity to be creative and inventive in implementation is not significantly diminished by working within a given external specification.`"

Brooks observes that, unlike other engineering disciplines, in software design and construction can overlap. He writes that the pace is quicker between design and construction, compared to other engineering disciplines. The tasks of specification and construction can therefore blend together. Builders can even start their work before the requirements are finalized, as code is easier to change than bricks and mortar.

Today, it is widely recognized that successful delivery of software requires architects and programmers to work closely together. While ivory tower architecture has been resoundingly rejected, there remains a need for some degree of architectural oversight. Programmers have a tendency to take a bottom-up approach to software construction, as our day-to-day work demands we focus on the design of individual features rather than of the overall system. For this reason, maintaining conceptual integrity is often overlooked by programmers working at the coalface. We still need architects, taking a more top-down approach to design, to fight entropy and maintain conceptual integrity in our systems.

== The second-system effect

Continuing the theme of the previous chapter, Brooks calls for "`thoroughgoing, careful, and sympathetic communication between architect and builder`". Brooks calls architecture an "`interactive discipline`". While he has argued for a clear separation between the roles of architect and builder, he does not mean that the two groups should work in isolation.

The division of work between architecture and implementation must be treated as a two-way conversation, Brooks writes. Early and continuous communication can give the architect good readings on cost, and open a dialog with the programmers on alternative (cheaper) implementations. Early and continuous communication also instills confidence in the design in the builders.

Architects should _suggest_, not _dictate_, implementation strategies, he writes. The builder, ultimately, has responsibility for the implementation, but might also suggest changes to the architecture. The architect must deal "`quietly and privately`" with ideas put forward by the builder – perhaps "`some minor feature may have unexpectedly large costs when the implementation is worked out`".

This collaborative approach requires what we would today label emotional intelligence and psychological safety. Soft skills, such as empathy and communication, are today widely recognized as essential for high-performing teams, even more so than hard technical expertise.

Brooks then moves on to the topic of this fifth chapter, which he calls the second-system effect. This is the idea that "version 1" of a new software system is often the best version, because it is simple and elegant. But the "second system" (ie. a later major version) tends to be over-engineered and bloated with features.

"`The general tendency is to over-design the second system, using all the ideas and frills that were cautiously sidetracked on the first one.`" The result is a "`big pile`". Brooks gives the example of the IBM 709, an upgrade to the IBM 704. While the 704 was "`very successful and clean`", the 709's "`operation set [was] so rich and profuse that only about half of it was regularly used`".

To counteract the second-system effect, Brooks writes that architects must practice self-discipline "`to avoid functional ornamentation and to avoid extrapolation of functions that are obviated by changes in assumptions and purposes`".

The second-system effect is alive and well. All continuously-developed software systems suffer from entropy. The worst ones eventually collapse under their own weight of complexity and ambition.

As a way to counteract the second-system effect, Brooks proposes that architects should assign a value to "`each little function`": "`capability _x_ is worth not more than _m_ bytes of memory and _n_ microseconds per invocation`", for example. Translating such benchmarks from system programming to modern application programming will require use of different metrics, but the principle remains a good one. We don't cost features in this way often enough. If we did, our software products might remain leaner, and more focused, for longer.

== Pilot systems

In chapter 11, titled "Plan to Throw One Away", Brooks proposes building pilot models or pilot systems as an intermediate step between the initial system design and the construction of the final system. The pilot system, which is intended to be thrown away and not given to customers as "version 1", helps to identify potential problems with the design before the final solution is built.

The idea is taken from chemical engineering, where a new production process is rarely taken straight from the lab to the factory in a single step. More typically, a pilot plant is built to give experience in scaling up production of the final product.

// "`Project after project designs a set of algorithms and then plunges into construction of customer-deliverable software on a schedule that demands delivery of the first thing built.`"

This intermediate step is equally necessary for programming products, but software engineers do not yet routinely field-test a pilot system before undertaking to deliver the real product. By 1995, this had become common practice, with "beta" versions. Brooks also advocates the use of "alpha" versions, which are prototypes with limited functionality.

Somewhat contradicting his observations in the earlier chapter on the second-system effect, Brooks writes that version 1 of a new software product is often too slow, too big, too hard to use, or some combination of all three. The idea of building version 1 as a disposable prototype is to reveal the flaws in the design before the final system is constructed.

// The first version of a large-scale software system may be too slow, too big, difficult to use, etc. You then have to solve these problems – hopefully yuu can do this piece-by-piece, but the worst case scenario is you will have to start over if the design proves to be fundamentally flawed...

[quote, Fred Brooks]
____
Plan to throw one away; you will, anyhow.
____

Brooks uses the analogy of letter writing, suggesting that successful software development depends a great deal on trial and error. The pilot system allows the process of trial-and-error to be played out in a throw-away "draft" system, which he argues is preferable to incrementally changing the production system mid-flight. (The idea is that you "`fail faster`" with the draft pilot system.)

This point-of-view has not stood up well. In a retrospective chapter in the 20th anniversary edition of _The Mythical Man-Month_, Brooks admits that the industry has instead embraced iterative and incremental development practices... The focus shifted instead on composing software from lots of reusable, ready-made modules of common behaviors, ... instead of relying on big, detailed up-front planning and design. Seasoned developers understand that our task is to write as little code as possible!

Nevertheless, what Brooks did get right was the need to plan for systems to change.

[quote, Fred Brooks]
____
The only constant is change itself.
____

Brooks observes that the role of computer programmers is to satisfy a need rather than to deliver a tangible product, and that "`both the actual need and the user's perception of that need will change as programs are built, tested, and used.`"

// Brooks writes that, for hardware products like cars and computers, the existence of a tangible object "serves to contain and quantize user demand for changes". But "both the tractability and the invisibility of the software product expose its builders to perceptual changes in requirements."

Embracing change is, of course, fundamental to genuinely-agile development practices such as Extreme Programming. In 1975 this was quite a novel way of looking at software delivery.

Brooks is advocating the agile principle of embracing change, 25+ years before the manifesto for agile software development is written. It is inevitable, he writes, that objectives and requirements will change, and changes in development strategies and techniques are also inevitable.

[quote, Fred Brooks]
____
The throw-one-away concept is itself just an acceptance of the fact that as one learns, he changes the design.
____

There are two things we need to do to embrace change, Brooks writes. We must prepare the system for change. And we must prepare the organization itself for change.

Brooks suggests that designing the software system for change is the easy part. Brooks suggests that using high-level programming languages, structured programming techniques, compile-time operations, and self-documenting techniques can reduce the risk of errors being introduced through incremental change. (Automated testing is not mentioned.) ... This is done through modularization, extreme subroutining (which today we would call abstraction), careful definition of module interfaces – and complete documentation of these. ... "Most important is the use of a high-level language and self-documenting techniques so as to reduce errors induced by changes." ... "Quantizaion of change is an essential technique. Every product should have numbered versions, and each version must have its own schedule and a freeze date, after which changes go into the next version."

=== Organizational change

Planning for organizational change is harder. The project boss must work at keeping the managers and the technical people as interchangeable as their talents allow; in particular, one wants to be able to move people easily between technical and managerial roles. ...

Plans, milestones, and schedules need to be treated as _tentative_, to facilitate change. But this is anathema to many organizations - where slippage of delivery plans is treated as a "failure of project management".

Agile - this is perhaps what we've got wrong. We have not explained _how_ organizations should implement the cultural change needed.

"Management structures also need to change as the system changes."

Brooks writes about how flat organizational structures can really help facilitate this. He gives the example of Bells Labs that abolished job titles and hierarchies to everyone was an equal "member of the technical staff".

Brooks says this fits well with his model of *surgical teams* as "it has the effect of making a senior man feel that he does not demean himself when he builds programs, and [it] removes the social obstacles that deprive him of that creative joy."

Brooks says that the surgical team is "the long-run answer to the problem of the flexible organization." He explains: "it becomes relatively easy to reassign a whole surgical team to a different programming task when the organizational changes are necessary."

=== Maintenance

Once a program is shipped to customers, afterward further delivery is called *maintenance* rather than *development* – the work now consists chiefly of repairing design defects. This may include adding features that are visible to the user.

Maintenance can cost 40% of the total cost of developing a software product. We tend to think of software development not as projects but as long-lived programs (products). ... Program maintenance consists chiefly of changes that repair design defects, add incremental function, or adapt to changes in the use environment or configuration.

More users = more bugs found = more maintenance. Maintenance cost is strongly related to the number of users, because the more users there are, the more bugs will be found. There's a drop-and-climb curve in bugs discovered per month over a product's life. Fixing a defect has a substantial (20% - 50%) chance of introducing another. After each fix, one must run the entire bank of test cases previously run against a system to ensure that it has not been damaged in some obscure way (what we now call _regression_).

image::./_/media/diagrams/bug-discovery-over-time.drawio.png[]

Methods of designing programs so as to eliminate, or at least illuminate, side effects can have an immense payoff in maintenance costs. So can methods of implementing designs with fewer people, fewer interfaces, and fewer bugs.

System entropy rises over time. All repairs tend to destroy structure, to increase the entropy and disorder of a system. Even the most skillful program maintenance only delays the program's subsidence into unfixable chaos, from which there has to be a ground-up redesign.

The bug rate drops off after the initial release, but then starts to gradually climb again -- this may be due to users fully exercising the new capabilities of the software, ie. they start to become really familiar with it, and so edge case bugs start to get shaken out.

Brooks discusses the far-reaching, often overlooked, impacts of doing lots of piecemeal repairs on a system. He sites studies by Lehman and Belady that "all repairs tend to destroy structure to increase the entropy and disorder of the system. ... As time passes, the system becomes less and less well-ordered. Sooner or later, the fixing ceases to gain any ground. Each forward step is matched by a backward one. Although in principle usable forever, the system has worn out as a base for progress."

Eventually, a "brand-new, from-the-ground-up redesign is necessary."

Brooks quotes CS Lewis: "Terrific energy is expanded – civilizations are built up – excellent institutions devised; but each time something goes wrong. Some fatal flaw always brings the selfish and cruel people to the top, and then it all slides back into misery and ruin."

Brooks concludes: "Systems program building is an entropy-decreasing process, hence inherently metastable. Program maintenance is an entropy-increasing process, and even ifs most skillful execution only delays the subsidence of the system into unfixable obsolescence."

Intriguingly, Brookes writes that "methods of designing programs so as to eliminate or at least illuminate side effects can have an immense payoff in maintenance costs." He suggests that having fewer people do the design and build, and having fewer interfaces, produces systems with fewer bugs – and such systems suffer less from entropy and therefore have longer useful lives.

== Communication

Building on the themes from the previous chapters, Brooks makes the argument that the most important skill in software development is communication.

Brooks asks: "`How does one keep the architects from drifting off into the blue with unimplementable or costly specifications?`" And: "`How does one ensure that every trifling detail of an architectural specification gets communicated to the implementer, properly understood by him, and accurately incorporated into the product?`"

In chapter six, titled "Passing the word", Brooks draws on a communication system worked out for the System/360 design effort. This was a hardware project, but Brooks says the techniques are equally applicable to software projects. He writes that there are two critical artifacts that need to be maintained to support communication between architects and builders:

* *The manual*: A external specification for the system, ie. a user manual, written by the architects. "`It describes and prescribes every detail of what the user sees`" and omits all the implementation details that the user does not see and which are left to the builders to decide. Feedback from users and implementers helps to refine the user interface design defined in the manual.

* *Formal definitions*: Formal interface definitions should be used to specify a system's internal interfaces. Formal notations are precise and complete, but lack comprehensibility, therefore good system documentation will consist of a mix of formal notations (for precision) and prose (for extra definition and comprehensibility).

Brooks notes that reference implementations – which may be just a "`simulation`" of the target system – can serve as a formal definitions of a system's design. An "`implementation can serve as a formal definition. When the first compatible computers were built, this was exactly the technique used. The new machine was to match an existing machine. The manual was vague on some point? 'Ask the machine!' … A programmed simulator… can serve in precisely the same way.`" Today, we might develop prototypes and proofs-of-concepts to serve as reference implementations. This has a number of advantages, not least prototypes can help to answer a lot of questions that can only be answered through implementation, such as performance trade-offs and resource requirements in the design.

// In chapter 10, Brooks says that "`a small number of documents become the critical pivots around which every project's management revolves`". For a computer development project, the critical documents are: the objectives, the specifications (including performance specifications), space allocations (memory), the schedule and budget, the organization chart and floor plan, and the estimate, forecast, and prices of the machine itself. Even on a small project, the manager should formalize such a set of documents. Preparing each document focuses thought and crystallizes discussion. The act of writing requires hundreds of mini-decisions – resulting in clear, exact policies, rather than fuzzy ones. The project manager's job, fundamentally, is to keep everyone going in the same direction.

Other important methods of communication, Brooks writes, include telephone logs, meeting minutes, and annual "supreme court sessions", typically lasting a couple of weeks, in which major architectural decisions are resolved, and prior decisions reviewed.

Most importantly, Brooks writes that product testing is a critical mode of communication between the architects and the implementers. The role of the tester, ultimately, is to find "`where the design decisions were not properly understood or accurately implemented`". Intriguingly, Brooks suggests that testing ought to be done "`early and simultaneously`" with design, and that product testing is best delegated to an external body. This independent product testing organization is responsible for checking the system against its requirements specifications, and serving as a devil's advocate, pinpointing every conceivable defect and discrepancy. "`Every development organization needs such an independent technical auditing group to keep it honest.`"

"`In the last analysis the customer is the independent auditor. In the merciless light of real use, every flaw will show. The product-testing group then is the surrogate customer, specialized for finding flaws.`"

Chapter seven, titled "Why did the Tower of Babel fail?", develops Brooks's communication theory further. Brooks uses the biblical story of the Tower of Babel as a metaphor for the communication breakdowns that can occur in large software projects. The Tower of Babel is a myth from the Book of Genesis that is meant to explain the existence of different languages and cultures around the world. According to the story, a united human race with a common language agree to build a great city with a mighty tower. Noticing humanity's power in unity and through common language, God confounds their speech so that the people can no longer communicate effectively with one another. The people fail to complete the engineering work, and scatter around the Earth, leaving Babel unfinished.

Brooks calls the tower of Babel "`the first engineering fiasco`". But it was not to be the last. The project failed, not because of lack of manpower, materials, time, or knowledge, but because the collaborators failed to communicate effectively with one another, and therefore they could not efficiently coordinate their individual efforts.

The same thing is the cause of many failures in the delivery of large computer systems, Brooks argues.

[quote, Fred Brooks]
____
Communication and its consequent, organization, are critical for success. The techniques of communication and organization demand from the manager much thought and as much experienced competence as the software technology itself.
____

Teams should communicate with one another in as many ways as possible. Brooks proposes a number of communication patterns, as well as artifacts that support them. He writes that communication should be centered on a project workbook, a "`centralized, up-to-date, and universally accessible repository of all of the project's documentation, including objectives, interface specifications, technical/internal specifications, technical standards, and administrative memoranda.`" Critically, the workbook must also record the changes made to the project over time.

Brooks goes into some length about how the OS/360 project soon ended up with a printed workbook _five inches thick_, with hundreds of pages being reprinted and replaced in a typical day. The project switched to using microfiche, which reduced the costs of maintaining by the workbook, by eliminating the cost of reprinting large numbers of copies of the whole workbook at regular intervals. But even in 1975, Brooks noted that a "shared electronic notebook" would be a much more effective, cheaper, and simpler mechanism, and might be the future!

== Performance

The ninth chapter, obscurely titled "Ten pounds in a five-pound sack", is all about using hardware resources efficiently. Much of this is no longer relevant to most types of software system developed today. Indeed, in a retrospective chapter in the 20th anniversary edition of _The Mythical Man-Month_, Brooks acknowledges that memory consumption limits had already been obsoleted, first by virtual memory and then by cheap real memory. By 1995, most computer users could buy enough real memory to hold all the code for all the major applications they run on their system. We take this for granted today – that we can run as many applications, or load as many browser tabs, as we like.

Nevertheless, there is much that we can learn from Brooks's 1975 analysis if we are serious about optimizing our software for performance. For example, Brooks says that size budgets should be tied to functions, such that each operation of a system must operate withing well-defined constraints – not only memory size, but also disk accesses, storage space, and so on.

Brooks also writes that, on large-scale software projects, individuals teams tend to optimize for the performance targets on their own module, rather than think about the total effect on the user. He writes this is a major hazard for achieving good performance in large-scale systems. It may no longer be true of monoliths, but it is certainly true of modern distributed systems like microservice architectures.

But perhaps most usefully of all, Brooks writes that high-performing systems – those that aee genuinely lean and fast – are the result of strategic innovations, such as well-designed algorithms, rather than tactical cleverness.

And the greatest performance optimizations can usually be found in the representation of data. Redoing the representation of data, or its storage tables, will often yield bigger performance improvements than optimizing the business logic, Brooks observes.

[quote, Fred Brooks]
____
Representation is the essence of programming.
____

== Sharp tools

"`A good workman is known by his tools`" Brooks writes in chapter 12. "`Each master mechanic has his own personal set [of tools], collected over a lifetime and carefully locked and guarded – the visible evidence of personal skills.`" These tools would be "`little editors, sorts, binary dumps, disk space utilities, etc.`"

But Brooks says that this is undesirable. In computer programming projects, where "`the essential problem is communication, [...] individualized tools hamper rather than aid communication.`" Brooks continues, "`it is obviously much more efficient to have common development and maintenance of general-purpose programming tools.`"

He advocates there be "`one toolmaker per team... [who] masters all the common tools and is able to instruct... in their use. He also builds the specialized tools his boss needs.`"

The rest of the chapter looks at the tools that Brooks recommends be standardized across a team. Today, we need not spend nearly so much time and effort thinking about our tooling. And we don't care so much about our systems being idle for long periods of time. For example, Brooks writes about methods for scheduling teams' access to limited testing machines… this is not relevant any more.

The chapter provides an interesting step back in time to when every aspect of software delivery had to be carefully considered – so much is now just readily available, often free or as a low-cost subscription.

"`The most important tools for system programming today are two that were not used in OS/360 development almost a decade ago. They are still not widely used [in 1975], but all evidence points to their power and applicability. They are (1) high-level language and (2) interactive programming. I am convinced that only inertia and sloth prevent the universal adoption of these tools; the technical difficulties are no longer valid excuses.`"

Brooks explains why the adoption of high-level languages (by which we mean higher than assembly) were still subject to push-back in 1975.

The combination of high-level language plus interactive programming makes for "`a pair of sharp tools indeed`", Brooks concludes.

== The whole and the parts

Chapter 13 is about "`how does one integrate a tested set of component programs into a tested and dependable system?`" It's about that last step of integrating and testing a complete, whole system from its pre-fabricated, pre-tested component parts. Of course today we do this incrementally – it's not all done in one step at the end.

This process is really about "`designing the bugs out`".

// === TODO ========================================================================================

Techniques that help include:

* *Conceptual integrity* makes a program easier to build, easier to use, and less subject to bugs.

* Painstaking architectural effort: "The crucial task is to get the product defined. Many, many failures concern exactly those aspects that were never quite specified." ... "careful function definition, careful specification, and the disciplined exercise of frills of function, and flights of technique all reduce the number of system bugs that have to be found."

"Long before the code exists, the specification must be handed to an outside testing group to be scrutinized for completeness and clarity."

This is not something we to today – it was perhaps only necessary in the very early days of development when it was costly to _change_ code. But it remains necessary if you want fixed budgets for delivery.

"[Developers] will happily invent their way through the gaps and obscurities."

The following ideas were relatively embryonic at the time, but Brooks clearly saw that these had potential:

*Top-down-design*

"I am persuaded that top-down design is the most important new programming formulation of the decade."

Brooks reviews a 1971 paper by Niklaus Wirth, title _Program Development by Stepwise Refinement", which formalized a design process that divided a system build into:

- Architecture
- Implementation
- Realization

The three are a series of _refinement steps_.

"One sketches a rough task definition and a rough solution method that achieves the principal result. Then one examines the definition more closely... and one takes the large steps of the solution and breaks them down into smaller steps."

"From this process one identifies _modules_ of solution or of data whose further refinement can proceed independently of other work."

You use a high-level notation for each step, exposing the concepts and concealing the details... until further refinement becomes necessary.

Top-down benefits:

* Clarity in the structure and representation
* Makes it easier to define requirements and functions
* Partitioning and independence of modules, reduces system bugs
* The suppression of details makes flaws in the design more apparent

You may still have to start over with a fresh high-level design, but this approach reduces the temptation to do the opposite: trying to salvage a bad design with lots of patches and "all kinds of cosmetic relief".

*Structured programming*

Structured programming is a programming paradigm characterized by source code that uses block-based source code structure to encode control flow such as sequence, selection (i.e. if-then-else and switch) and iteration (i.e. for and while).

Originally, the central goal of the structured programming movement was to eliminate the need for and use of the goto statement. As goto provides powerful and flexible flow control, it can be used to write any arbitrarily complex algorithm, but the resulting code often has significant quality issues, commonly described as spaghetti code. Structured programming replaces goto with constructs that tend to result in better code. The paradigm became popular and for the most part achieved the goal of supplanting goto. In fact, its ubiquity is so thorough that for much of software development, it is simply the way code is written, no longer a topic of discussion as it once was.

Structured programming was a new idea at the time. Brooks writes there is merit in the idea!

*Component debugging*

Prior 20 years saw great leaps forward in approached to debugging programs, from "on-machine debugging" to "interactive debugging" (ie. step-throughs and breakpoints).

These tools have changed more substantially still in the last 50 years. But the fundamentals were already formed in the 1970s.

Brooks identified *system debugging* as one of the hardest things to do in 1975. He says you should expect it to take longer than you think it will.

He says system debugging must be done "debugged components" – what we would now call unit tests (then: component tests).

There is a nod toward integration testing – "using the pieces to test each other". The case for going straight to system testing is the reduced effort of needing to do lots of test scaffolding.

Scaffolding = all programs and data built for debugging and testing purposes, but not intended to be included in the final product.

"It is not unreasonable for there to be half as much code in scaffolding as there is in product."

Forms of scaffolding:

* Dummy components: interfaces and faked data.
* Miniature file
* Auxiliary programs: generators for test data, etc.

''''

Detailed architectural effort (discussed in earlier chapters) not only improves the *ease of use* of a software product, but also makes it easier to build, and reduces the number of defects.

Many defects concern aspects that were never quite fully specified.

Brooks suggests that, before any code itself is written, the specification should be handed to an outside testing group to be scrutinized for completeness and clarity. The developers themselves cannot do this.

"Wirth's top-down design [by stepwise refinement] is the most important new programming formalization of the [1965-1975] decade." Wirth advocates using as high-level a notation as possible on each step.

A good top-down design avoids bugs in four ways:

1. xxx
2. xxx
3. xxx
4. xxx

Sometimes one has to go back, scrap a high level, and start over.

*Structured programming* (designing programs whose control structures consist only of a specified set that govern blocks of code, versus miscellaneous branching) is a sound way to avoid bugs and is the right way to think.

System debugging is far harder than component debugging. It helps to plan system debugging sessions before starting – ie. have a strategy, a systematic and planned approach.

System debugging should begin only after all the components are proven to work. Do not use system testing to try to smoke out interface bugs.

Add one component at a time during system debugging.

It is worthwhile to build lots of debugging scaffolding and test code – this might account for as much as 50% as much of the product being debugged.

One must control and document changes and versions, with team members working on *playpen* copied.

== Hatching a catastrophe

In chapter 14, Brooks suggests the use of [PERT charts] to keep track of critical tasks in a project.

"How does a project get to be a year late?… One day at a time."

Day-by-day schedule slippage is harder to recognize, harder to prevent, and harder to make up, than calamities.

The first step in controlling a big project on a tight schedule is to _have_ a schedule – made up of milestones and dates for them. Milestones must be concrete, specific, measurable events defined with knife-edge sharpness.

Chronic schedule slippage is a morale-killer.

_Hustle_ is essential for great programming teams, just as for great baseball teams.

There is no substitute for a critical-path schedule. The preparation of the critical-path schedule is the most valuable part of its use; this process identifies the dependencies, and estimating the components forces a great deal of very specific planning very early in a project.

Delivery managers need accurate status reports. Accepting status reports without panic or preemption will encourage honest reporting. Status reviews must be shared.

////

"How does a project get to be a year late? ... One day at a time." – Sophacles

Why are projects late?

Many disasters are caused by termites, not tornadoes!

Major incidents are actually easier to handle – the whole team rises to the occasion.

The problem is when the schedule slips imperceptibly. "Day-to-day slippage is harder to reorganize, harder to prevent, harder to make-up."

''''

How does one control a big project on a tight schedule?

First: have a schedule! This means having clearly-defined events, called *milestones*, that have a date. The milestones must be concrete, eg. "debugging version passed 100% of test cases". Milestones must be "shard edged and unambiguous" – then you can't lie that you'vce delivered what you said you would, because it's verifiable.

"The fuzzy milestone is the harder burden to live with."

Brooks suggests the use of PERT charts. "The preparation of a PERT chart is the most valuable part of its use. Laying out the network, identifying the dependencies... force a great deal of very specific planning very early in a project."

Brooks suggests a dedicated sub-team, calls the Plans and Controls team. He says this is "invaluable for a large project". It works better when these people are not directly involved in the building, but are regularly reviewing its progress.

"The Plans and Controls group is the watchdog who renders imperceptible delays visible andd who points up the critical elements. It is the early warning system against losing a year, one day at a time."

////

== The other face

Chapter 15 provides guidance on documenting large programs. The book also summarizes modeling notations that were popular at the time, and he draws comparisons between [top-down] and [bottom-up] approaches to system design.

This is all about *user documentation* (as opposed to developer documentation).

The documentation is "the other face" of the product to the user. This is just as important as the product itself.

Even for the most private of programs, prose documentation is necessary, for memory will fail the user-author.

But user documentation is rarely done very well. There are many reasons for this, including schedule pressure, but Brooks identifies knowledge of _how_ to document effectively as being a key reason. Technical writing, still in 2025, is a neglected art, and rarely appears listed in job requirements.

Most documentation fails in giving too little _overview_. Good documentation will stand way back, then zoom in slowly.

Critical user documentation should be drafted before the program is built, for it embodies basic planning decisions. It should describe nine things:

1. xxxx
2. xxxx
3. xxxx
4. xxxx
5. xxxx
6. xxxx
7. xxxx
8. xxxx
9. xxxx

A program should be shipped with a few test cases, some for valid input data, some for borderline input data, and some for clearly invalid input data – this is for the benefit of end users.

Developer documentation – documentation for program internals, for the people who must modify the program – should contain five kinds of things:

1. xxxx
2. xxxx
3. xxxx
4. xxxx
5. xxxx

The flow chart is the most oversold piece of program documentation. Logic diagrams have been made obsolete by high-level programming language. A flow chart is just a _diagrammed high-level language – so it's redundant.

To keep documentation maintained, is is crucial that is be incorporated into the source program, rather than be kept as a separate document.

Three notions are key to minimizing the volume of documentation:

* Use parts of the program that have to be there anyway, such as names and declarations, to carry as much of the documentation as possible.

* Use space and format to show subordination and nesting to improve readability.

* Insert the necessary prose documentation into the program as paragraphs of comments, especially in module headers.

In documentation for use by program modifiers, tell _why_ things are like they are, rather than merely _how_ they are. _Purpose_ is the key to understanding; even high-level language syntax does not at all convey purpose.

Self-documenting programming techniques find their greatest use and power in high-level languages used with on-line systems, which are the tools one _should_ be using.

////

This chapter is essentially about user-facing documentation, or more generally user-interfaces – it's what tels users how to use a program.

The problem is that the user is remote from the developers in both time and space.

"For the program product, the other face to the user is fully as important as the face to the machine."

In the 1960s/1970s, the effort was getting complex programs to work! "A computer program is a message from a man to the machine."

Today, we often start the other way around – at the UI.

Brooks writes that lots of levels of documentation are required:

* Purpose
* Environment
* Domain and range of output
* Functions realized
* Algorithms used
* I/O formats
* Operating instructions
* Options
* Running time
* Accuracy and checking

Brooks advocates that development and maintenance of UI documentation be done in conjunction with changes to the program itself.

(Most of this chapter is not relevant any more – users don't require such low-level documentation.)

*Self-documenting programs* - this idea is closer to how we think about UXD today.

"We typically attempt to maintain a machine-readable form of a program and an independent set of human readable documentation."

Better for these to coexist side-by-side. They change together, and therefore remain in sync.

"The solution, I think, is to merge the files, to incorporate the documentation in the source program."

Enforces proper maintenance of user documentation - as part of the UI.

Such programs are called *self-documenting*.

He then goes on to explain how this might be achieved in the programs of the 1960s and 1970s. It was hard! But, Brooks writes, it is becoming easier in high-level languages.

////

== No silver bullet

Chapter 16

Republication of Brooks's classic 1986 paper https://www.cs.unc.edu/techreports/86-020.pdf["No Silver Bullet – Essence and Accidents of Software Engineering"].

// Title: "No silver bullet - essence and accident"

// The concept of a “silver bullet” comes from European folklore, where silver was believed to be the only weapon capable of killing supernatural creatures like werewolves, vampires, and witches. Over time, it evolved into a metaphor for a simple, miraculous solution to a complex problem.

////

Brooks argues that "there is no single development, in either technology or management technique, which by itself promises even one order of magnitude [tenfold] improvement within a decade in productivity, in reliability, in simplicity." He also states that "we cannot expect ever to see two-fold gains every two years" in software development, as there is in hardware development (Moore's law).

Brooks distinguishes between two different types of complexity: accidental complexity and essential complexity. This is related to Aristotle's classification. Accidental complexity relates to problems that engineers create and can fix. For example, modern programming languages have abstracted away the details of writing and optimizing assembly language source code and eliminated the delays caused by batch processing, though other sources of accidental complexity remain. Essential complexity is caused by the problem to be solved, and nothing can remove it; if users want a program to do 30 different things, then those 30 things are essential and the program must do those 30 different things.

Brooks claims that accidental complexity has decreased substantially, and today's programmers spend most of their time addressing essential complexity. Brooks argues that this means shrinking all the accidental activities to zero will not give the same order-of-magnitude improvement as attempting to decrease essential complexity. While Brooks insists that there is no one silver bullet, he believes that a series of innovations attacking essential complexity could lead to significant improvements. One technology that had made significant improvement in the area of accidental complexity was the invention of high-level programming languages, such as Ada.[1]

Brooks advocates "growing" software organically through incremental development. He suggests devising and implementing the main and subprograms right at the beginning, filling in the working sub-sections later. He believes that computer programming this way excites the engineers and provides a working system at every stage of development.

Brooks goes on to argue that there is a difference between "good" designers and "great" designers. He postulates that as programming is a creative process, some designers are inherently better than others. He suggests that there is as much as a tenfold difference between an ordinary designer and a great one. He then advocates treating star designers equally well as star managers, providing them not just with equal remuneration, but also all the perks of higher status: large office, staff, travel funds, etc.

The article, and Brooks's later reflections on it, "'No Silver Bullet' Refired", can be found in the anniversary edition of The Mythical Man-Month.[2]


////

== "No silver bullet" revisited

Chapter 17

// (Supplementary chapter in the 20th anniversary edition)

== Concluding thoughts

_The Mythical Man-Month_ is the book that everyone claims to have read, but few have. But I would encourage everyone to do so. It's a wonderfully imaginative book, rich in metaphor and analogy, and filled with pearls of wisdom. It's a must-read for anyone working in the software industry. The 20th anniversary edition is recommended for its extended content.

What I learnt from _The Mythical Man-Month_ is that modern best practices in software development are deeply rooted. The seeds for our current ways of working were sown here, in the 1960s and 1970s, when we started to push the boundaries of what software could do. Almost all of the ideas put forward by Fred Brooks in this book are just as relevant in 2025 as they were in 1975.

// Much of this is no longer relevant, due to advances in hardware and the reduced constraints under which we must design software to operate. For example, Brooks says that memory consumption limits is a crucial decision, because performance is so closely related to the transient area. But even 20 years later, Brooks acknowledges that this decision has been obsoleted, first by virtual memory and then by cheap real memory. Users now buy enough real memory to hold all the code for all of the major applications they run on their system.

// Aside from the running time, the _memory space_ occupied by a program is a principal cost. This is especially true of operating systems, where much is resident (in memory) all the time.

Of course, some of the challenges today are different from what they were in the time of OS/360. We are no longer physically constrained by computing resources. Hardware is abundant, easily sourced, and cheap. Yet physical constraints remain for many categories of software – real-time systems, embedded systems, and systems with strict performance requirements, for example.

The management of complexity remains the core challenge of software development. Throughout the history of computing, advances in technology have created opportunities for ever more ambitious software. Today, the resources and tools at our disposal are as powerful as they have ever been – think cloud computing, virtualization and containerization, continuous integration and automated deployment pipelines, and AI-assisted coding environments. But the productivity gains afforded by these tools are offset by the increases in complexity of the software that we try to make today.

The book closes with this epilogue:

[quote, Fred Brooks]
____
The tar pit of software engineering will continue to be sticky for a long time to come. One can expect the human race to continue attempting systems just within or just beyond our reach; and software system's are perhaps the most intricate and complex of man's handiworks. The management of this complex craft will demand our best use of new languages and systems, our best adaptation of proven engineering management methods, liberal doses of common sense, and a God-given humility to recognize our fallibility and limitations.
____

Amen.

''''

== Related reading

* https://curtclifton.net/papers/MoseleyMarks06a.pdf[Out of the Tar Pit] — 2006 paper by Ben Moseley and Peter Marks.
